{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd7e5389",
   "metadata": {},
   "source": [
    "Run the cell below if you are using Google Colab to mount your Google Drive in your Colab instance. Adjust the path to the files in your Google Drive as needed if it differs.\n",
    "\n",
    "If you do not use Google Colab, running the cell will simply do nothing, so do not worry about it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "559c836e",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive/')\n",
    "    %cd 'drive/My Drive/Colab Notebooks/04_Classification'\n",
    "except ImportError as e:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d92f635",
   "metadata": {},
   "source": [
    "# More Classifiers, Evaluation Methods & Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdcff672",
   "metadata": {},
   "source": [
    "In this exercise, we will use the **Iris dataset**, which you can find in **data/iris.csv**. \n",
    "\n",
    "The dataset describes three types of Iris flowers:\n",
    "- Setosa\n",
    "- Virginica\n",
    "- Versicolour\n",
    "\n",
    "There are four (non-class) attributes\n",
    "- Sepal width and length\n",
    "- Petal width and length\n",
    "\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"imgs/iris_dataset_meme.png\" style=\"width: 60%;\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ecbb9cda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SepalLength</th>\n",
       "      <th>SepalWidth</th>\n",
       "      <th>PetalLength</th>\n",
       "      <th>PetalWidth</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SepalLength  SepalWidth  PetalLength  PetalWidth         Name\n",
       "0          5.1         3.5          1.4         0.2  Iris-setosa\n",
       "1          4.9         3.0          1.4         0.2  Iris-setosa\n",
       "2          4.7         3.2          1.3         0.2  Iris-setosa\n",
       "3          4.6         3.1          1.5         0.2  Iris-setosa\n",
       "4          5.0         3.6          1.4         0.2  Iris-setosa"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# load the data\n",
    "iris = pd.read_csv(\"data/iris.csv\")\n",
    "iris.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6fba93e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SepalLength</th>\n",
       "      <th>SepalWidth</th>\n",
       "      <th>PetalLength</th>\n",
       "      <th>PetalWidth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SepalLength  SepalWidth  PetalLength  PetalWidth\n",
       "0          5.1         3.5          1.4         0.2\n",
       "1          4.9         3.0          1.4         0.2\n",
       "2          4.7         3.2          1.3         0.2\n",
       "3          4.6         3.1          1.5         0.2\n",
       "4          5.0         3.6          1.4         0.2"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separate the training features and target variable\n",
    "iris_data = iris[['SepalLength','SepalWidth','PetalLength','PetalWidth']]\n",
    "\n",
    "# Encode the target variable\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "iris_target = label_encoder.fit_transform(iris['Name'])\n",
    "\n",
    "iris_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d3d21a",
   "metadata": {},
   "source": [
    "# Naive Bayes (NB)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a94cb1f",
   "metadata": {},
   "source": [
    "## Bayes Theorem\n",
    "\n",
    "Fundamental theorem in probability that describes how to update our belief about an event based on new evidence.\n",
    "- It computes the **conditional probability $P(C|A)$** that tells us the probability of a class C given some attribute A\n",
    "\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"imgs/bayes_theorem.png\" style=\"width: 60%;\">\n",
    "</div>\n",
    "\n",
    "- **P(C|A)** is the **posterior / conditional probability**: the probability of class $C$ _after_ attribute $A$ is seen  \n",
    "- **P(A|C)** is the **likelihood / class-conditional probability**: the probability of observing attribute $A$ given class $C$ \n",
    "- **P(C)**: is the **prior probability of class C**: the initial probability of class $C$ _before_ attributes are seen\n",
    "- **P(A)** is the **marginal probability**: the total probability of attribute $A$ across all possible classes\n",
    "\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"imgs/baes_theorem.jpeg\" style=\"width: 60%;\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24df63ef",
   "metadata": {},
   "source": [
    "## Naive Bayes Classifier\n",
    "\n",
    "The Naive Bayes Classifier is a simple classification algorithm based on Bayes' Theorem.\n",
    "\n",
    "Let's classify whether an email is **Spam** or **Not Spam**. We have a dataset of **5 emails** with the words **\"Offer\"** and **\"Free\"** and their corresponding class labels.\n",
    "\n",
    "| Email | Word: \"Offer\" | Word: \"Free\" | Class (Spam/Not Spam) |\n",
    "|--------|------------|------------|--------------------|\n",
    "| 1      | Yes        | Yes        | Spam              |\n",
    "| 2      | Yes        | No         | Spam              |\n",
    "| 3      | No         | Yes        | Spam              |\n",
    "| 4      | Yes        | Yes        | Not Spam          |\n",
    "| 5      | No         | No         | Not Spam          |\n",
    "\n",
    "üìù **Feature Representation:**  \n",
    "- **Yes (1)** means the word is present in the email.  \n",
    "- **No (0)** means the word is absent.\n",
    "\n",
    "\n",
    "### How does Naive Bayes Work?\n",
    "\n",
    "#### 1. Compute the prior probabilites $P(C_j)$\n",
    "- For each class $C_j$, count the records in the training set that are labeled with class $C_j$ and divide the count by the overall number of records\n",
    "    \n",
    "---------------------------------------------------------------------------------------------------------   \n",
    "    \n",
    "$P(\\text{Spam}) = \\frac{\\text{Number of Spam Emails}}{\\text{Total Emails}} = \\frac{3}{5} = 0.6$\n",
    "\n",
    "$P(\\text{Not Spam}) = \\frac{\\text{Number of Not Spam Emails}}{\\text{Total Emails}} = \\frac{2}{5} = 0.4$\n",
    "\n",
    "---------------------------------------------------------------------------------------------------------   \n",
    "\n",
    "    \n",
    "#### 2. Estimate the class-conditional probability $P(A|C)$\n",
    "   \n",
    "   - ‚ö†Ô∏è Naive Bayes **assumes** that all **features** are **conditionally independent** (**Naive Bayes assumption**)\n",
    "   \n",
    "   - **Important**: this independence assumption is almost never correct!\n",
    "   \n",
    "   - ‚úÖ Thanks to the _independence assumption_, we can re-write the joint probabiity $P(A|C)$ as the product of the invididual probabilities $P(A_i|C_j)$ (which we can estimate directly from the training data for all $A_i$ and $C_j$):\n",
    "   \n",
    "   $P(A_1, A_2, ..., A_n|C_j) = P(A_1|C_j) \\times P(A_2|C_j) \\times ... \\times P(A_n|C_j) = \\prod_{i=1}^n P(A_i|C_j)$\n",
    "   \n",
    "   - **In practice**: Estimate  $P(A_i|C_j)$ by counting how often an attribute value co-occurs with class $C_j$, and divide by the overall number of examples belonging to class $C_j$\n",
    "   \n",
    "---------------------------------------------------------------------------------------------------------   \n",
    "\n",
    "**For Spam emails**:\n",
    "\n",
    "$\n",
    "P(\\text{\"Offer\"} | \\text{Spam}) = \\frac{\\text{Spam emails containing \"Offer\"}}{\\text{Total Spam emails}} = \\frac{2}{3} = 0.67\n",
    "$\n",
    "\n",
    "$\n",
    "P(\\text{\"Free\"} | \\text{Spam}) = \\frac{\\text{Spam emails containing \"Free\"}}{\\text{Total Spam emails}} = \\frac{2}{3} = 0.67\n",
    "$\n",
    "\n",
    "**For Not Spam emails**:\n",
    "\n",
    "$\n",
    "P(\\text{\"Offer\"} | \\text{Not Spam}) = \\frac{\\text{Not Spam emails containing \"Offer\"}}{\\text{Total Not Spam emails}} = \\frac{1}{2} = 0.5\n",
    "$\n",
    "\n",
    "$\n",
    "P(\\text{\"Free\"} | \\text{Not Spam}) = \\frac{\\text{Not Spam emails containing \"Free\"}}{\\text{Total Not Spam emails}} = \\frac{1}{2} = 0.5\n",
    "$\n",
    "\n",
    "---------------------------------------------------------------------------------------------------------   \n",
    "\n",
    "\n",
    "#### 3. Apply Bayes' Theorem\n",
    "\n",
    "- The probability of a sample $A$ belonging to class $C_j$ is: $P(C_j|A) = \\frac{P(A|C_j)P(C_j)}{P(A)}$\n",
    "- Since **$P(A)$** is the **same for all classes**, we can compare probabilities using $P(C_j|A) \\propto P(C_j) \\prod_{i=1}^n P(A_i|C_j)$\n",
    "    \n",
    "---------------------------------------------------------------------------------------------------------   \n",
    "\n",
    "Suppose we receive a **new email**:  üìß **\"Offer Free\"** (contains both words \"Offer\" and \"Free\")\n",
    "\n",
    "**For Spam**:\n",
    "\n",
    "$\n",
    "P(\\text{Spam} | \\text{\"Offer\", \"Free\"}) \\propto P(\\text{\"Offer\"} | \\text{Spam}) \\times P(\\text{\"Free\"} | \\text{Spam}) \\times P(\\text{Spam})\n",
    "$\n",
    "\n",
    "$\n",
    "= (0.67) \\times (0.67) \\times (0.6) = 0.267\n",
    "$\n",
    "\n",
    "**For Not Spam**:\n",
    "\n",
    "$\n",
    "P(\\text{Not Spam} | \\text{\"Offer\", \"Free\"}) \\propto P(\\text{\"Offer\"} | \\text{Not Spam}) \\times P(\\text{\"Free\"} | \\text{Not Spam}) \\times P(\\text{Not Spam})\n",
    "$\n",
    "\n",
    "$\n",
    "= (0.5) \\times (0.5) \\times (0.4) = 0.1\n",
    "$\n",
    "\n",
    "---------------------------------------------------------------------------------------------------------   \n",
    "\n",
    "\n",
    "#### 4. Classification Decision\n",
    "- Assign A to the class that **maximizes** the posterior probability, i.e., the class with the highest probability: $\\hat{C} = arg max_{C_j} P(C_j) \\prod_{i=1}^n P(A_i|C_j)$\n",
    "    \n",
    "---------------------------------------------------------------------------------------------------------   \n",
    "\n",
    "Since **0.267 (Spam) > 0.1 (Not Spam)**, we classify the email as **Spam**. üöÄ\n",
    "\n",
    "---------------------------------------------------------------------------------------------------------   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2689c43",
   "metadata": {},
   "source": [
    "### ‚ö†Ô∏è  Zero-Frequency Problem\n",
    "\n",
    "This problem occurs in Naive Bayes classification when a feature value **never appears** in the training set for a particular class. This leads to a **zero class-conditional probability**, which causes problems when computing the final probability using Bayes' theorem.\n",
    "\n",
    "#### Why Is This a Problem?\n",
    "If any feature $A_i$ has $P(A_i|C_j)=0$, then the entire product becomes **zero**, making it impossible to classify the instance correctly.\n",
    "\n",
    "#### Solution: Laplace Smoothing\n",
    "\n",
    "Add a small constant $\\alpha$ (i.e., usually 1) to each probability estimate\n",
    "    \n",
    "- Original: $P(A_i|C_j) = \\frac{N_{ic}}{N_c}$\n",
    "- Laplace: $P(A_i|C_j) = \\frac{N_{ic} + 1}{N_c + c}$\n",
    "\n",
    "where $c$ = number of attribute values of $A$\n",
    "\n",
    "‚úÖ Probabilities will never be zero!\n",
    "\n",
    "‚úÖ Stabilizes probability estimates\n",
    "\n",
    "## Strengths\n",
    "- Works very well, even is the independence assumption is violated\n",
    "- **Robust** to **isolated noise points**, as they will be averaged out\n",
    "- **Robust** to **irellevant attributes**, as $P(A_i|C_j)$ is distributed uniformly for $A_i$\n",
    "- **Computationally cheap**: probabilities can be estimated doing one pass over the training data\n",
    "- **Memory efficient**: storing the probabilities does not require a lot of memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d1604e1",
   "metadata": {},
   "source": [
    "## Naive Bayes in Scikit-learn\n",
    "\n",
    "[Naive Bayes](https://scikit-learn.org/stable/modules/naive_bayes.html) is implemented in different variations in scikit-learn.\n",
    "They differ mainly by the assumptions they make regarding the distribution of $P(x_i|y)$\n",
    "\n",
    "\n",
    "- [```GaussianNB``` class](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html#sklearn.naive_bayes.GaussianNB) implements the Naive Bayes classifier for continious (numeric) features. Likelihood of the features is assumed to be Gaussian\n",
    "- [```MultinomialNB``` class](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html) implements the Naive Bayes classifier for discrete (categorical) features (multinomially distributed data)\n",
    "- [```BernoulliNB``` class](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.BernoulliNB.html) assumes multivariate Bernoulli distributions\n",
    "- [```CategoricalNB``` class](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.CategoricalNB.html) assumes that each feature has its own categorical distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11eb0cc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"‚ñ∏\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"‚ñæ\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GaussianNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>GaussianNB</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.naive_bayes.GaussianNB.html\">?<span>Documentation for GaussianNB</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>GaussianNB()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "naive_bayes = GaussianNB()\n",
    "naive_bayes.fit(iris_data, iris_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90de2cf",
   "metadata": {},
   "source": [
    "# Support Vector Machines (SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c78ff91a",
   "metadata": {},
   "source": [
    "## What is SVM?\n",
    "\n",
    "It's a machine learning algorithm used for classification and regression. It classifies data by finding an optimal line or hyperplane that maximizes the distance between each class in an N-dimensional space.\n",
    "\n",
    "## How does SVM work?\n",
    "\n",
    "Find a linear hyperplance (decision boundary) that **maximizes** the margin to the closest points (support vectors).\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"imgs/svm_1.png\" style=\"width: 60%;\">\n",
    "</div>\n",
    "\n",
    "\n",
    " ‚ö†Ô∏è If the **decision boundary is not linear**, then transform the data into a higher dimensional space using a **Kernel function**.\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"imgs/svm_2.png\" style=\"width: 60%;\">\n",
    "</div>\n",
    "\n",
    "\n",
    "## Strenghts\n",
    "\n",
    "- Works well in **high dimensional spaces** (i.e., many features)\n",
    "- **Memory efficient**: it uses a subset of training points in the decision function (i.e., suppprt vectors)\n",
    "- **Versatile**: different Kernel functions can be specified for the decision function\n",
    "- Can handle **non-linear data** using the kernel trick.\n",
    "\n",
    "\n",
    "\n",
    "## Limitations\n",
    "- **Computationaly expensive** on large datasets, especially when using complex kernels\n",
    "- **Difficult to choose the right kernel**: the choice of kernel (e.g., linear, polynomial, RBF) is crucial and requires hyperparameter optimization\n",
    "- **Hard to interpret**: the decision boundary is abstract and hard to interpret, especially in high-dimensional spaces"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6be1de",
   "metadata": {},
   "source": [
    "## SVM in Python\n",
    "\n",
    "[Support Vector Machines](https://scikit-learn.org/stable/modules/svm.html) are also implemented in different variations.\n",
    "\n",
    "We will be using the [```SVC``` class](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html) which implements support vector classification.\n",
    "An alternative implementation with different parameters is the [```NuSVC``` class](https://scikit-learn.org/stable/modules/generated/sklearn.svm.NuSVC.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd43c20f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"‚ñ∏\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"‚ñæ\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(gamma=&#x27;auto&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>SVC</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.svm.SVC.html\">?<span>Documentation for SVC</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>SVC(gamma=&#x27;auto&#x27;)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "SVC(gamma='auto')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svm = SVC(gamma='auto')\n",
    "svm.fit(iris_data, iris_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6015bf4d",
   "metadata": {},
   "source": [
    "# Artificial Neural Networks (ANN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "239c666b",
   "metadata": {},
   "source": [
    "## Perceptron: The Simplest Neural Unit\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"imgs/ann_1.png\" style=\"width: 60%;\">\n",
    "</div>\n",
    "\n",
    "## Multi-layer ANNs\n",
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"imgs/ann_2.jpg\" style=\"width: 60%;\">\n",
    "</div>\n",
    "\n",
    "### Training\n",
    "1. Initialize the weights ($w_0$, $w_1$, ..., $w_n$), either randomly or using pretrained weights\n",
    "2. Adjust the weights such that the output of the ANN is as consistent as possible with the class labels of the training examples:\n",
    "    - Using an **objective function**, e.g. $E = \\sum_i [Y_i - f(w_i, X_i)]^2$\n",
    "    - Find the weights $w_i$ that minimize $E$ using **backpropagation**\n",
    "    - Adjustment factor: **learning rate**\n",
    "    \n",
    "    <div style=\"text-align: center;\">\n",
    "        <img src=\"imgs/backprop.png\" style=\"width: 60%;\">\n",
    "    </div>\n",
    "    \n",
    "\n",
    "### Differences compared to the perceptron\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"imgs/ann_3.png\" style=\"width: 60%;\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139a901e",
   "metadata": {},
   "source": [
    "# Evaluation Methods\n",
    "\n",
    "**Goal**: Obtain a reliable estimate of the model's gneralization performance\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"imgs/evaluation_meme.jpg\" style=\"width: 40%;\">\n",
    "</div>\n",
    "\n",
    "## ‚ö†Ô∏è NEVER EVER TEST A MODEL ON DATA THAT WAS USED FOR TRAINING!!‚ö†Ô∏è \n",
    "\n",
    "**General approach**: split the labeled records into a training set and a test set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e98746",
   "metadata": {},
   "source": [
    "## Holdout Method\n",
    "\n",
    "This methout reserves a certain amount of the labeled data for testing, and uses the remainder for training.\n",
    "- Applied when **lots of sample data** is available\n",
    "- Typical train / test splits: 75% / 25% or 80% / 20%\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"imgs/holdout_method.png\" style=\"width: 60%;\">\n",
    "</div>\n",
    "\n",
    "‚ö†Ô∏è Random samples might not be representative for imbalanced datasets, as few or no records of the minority class will be in the training or test sets\n",
    "\n",
    "- **Stratified Sampling**: Sample each class independently, so that records of the minority class are present in each sample\n",
    "- **Random Subsampling**: Repeat the process with different subsamples, i.e., in each iteration, a certain proportion is randomly selected for training and the performance of the different iterations is averaged"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a10e9c",
   "metadata": {},
   "source": [
    "## Leave One Out Method\n",
    "\n",
    "It iterates over all examples as follows:\n",
    "- Train a model on all examples but the current one\n",
    "- Evaluate on the current example\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"imgs/leave_one_out_method.jpg\" style=\"width: 60%;\">\n",
    "</div>\n",
    "\n",
    "‚úÖ Produces very accurate estimates\n",
    "\n",
    "‚ùå Computationally infeasible "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94029335",
   "metadata": {},
   "source": [
    "## Cross-Validation\n",
    "\n",
    "**K-fold cross-validation**:\n",
    "- Splits the data into **k equally sized subsets** (usually $k=10$ and stratified sampling is used)\n",
    "- Each subset in turn is used for testing, and the remainder for training\n",
    "- The error estimates are averaged over all subsets to yield the overall error estimate\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"imgs/cross_validation.png\" style=\"width: 60%;\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "592e87b6",
   "metadata": {},
   "source": [
    "### Cross-Validation in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fdae0df5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0: Accuracy = 100.0%\n",
      "Fold 1: Accuracy = 93.33333333333333%\n",
      "Fold 2: Accuracy = 100.0%\n",
      "Fold 3: Accuracy = 93.33333333333333%\n",
      "Fold 4: Accuracy = 93.33333333333333%\n",
      "Fold 5: Accuracy = 86.66666666666667%\n",
      "Fold 6: Accuracy = 93.33333333333333%\n",
      "Fold 7: Accuracy = 93.33333333333333%\n",
      "Fold 8: Accuracy = 100.0%\n",
      "Fold 9: Accuracy = 100.0%\n",
      "Average Accuracy = 95.33333333333334%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt = DecisionTreeClassifier()\n",
    "\n",
    "accuracy_iris = cross_val_score(dt, iris_data, iris_target, cv=10, scoring='accuracy')\n",
    "\n",
    "for i, acc in enumerate(accuracy_iris):\n",
    "    print(\"Fold {}: Accuracy = {}%\".format(i, acc * 100.0))\n",
    "\n",
    "print(\"Average Accuracy = {}%\".format(accuracy_iris.mean() * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0da596d",
   "metadata": {},
   "source": [
    "### Stratified Sampling in Cross Validation\n",
    "\n",
    "You can control how the folds are created by changing the ```cv``` parameter.\n",
    "Stratified sampling is implemented in the [```StatifiedKFold``` class](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa8a8127",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.9466666666666667)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "cross_val = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "accuracy_iris = cross_val_score(dt, iris_data, iris_target, cv=cross_val, scoring='accuracy')\n",
    "accuracy_iris.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c680df8",
   "metadata": {},
   "source": [
    "### Obtaining predictions by cross-validation\n",
    "\n",
    "If you want to analyse the predictions made during cross validation (for error analysis, you don't apply cross validation when actually applying the model!), you can use the [```cross_val_predict()``` function](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_predict.html).\n",
    "\n",
    "**Note**: As the folds of a cross validation are non-overlapping, you get exactly one prediction for every example in your dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b69275e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "predicted = cross_val_predict(dt, iris_data, iris_target, cv=10)\n",
    "\n",
    "display(predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26815444",
   "metadata": {},
   "source": [
    "### Manual Cross Validation \n",
    "If you want to implement cross validation yourself, you can iterate over the folds manually:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "025be8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sometimes you have to use the raw array and not the pandas dataframe (access it with .values)\n",
    "data = iris_data.values \n",
    "target = iris['Name']\n",
    "\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "for train_indices, test_indices in cv.split(data, target):\n",
    "    train_data = data[train_indices]\n",
    "    train_target = target[train_indices]\n",
    "    \n",
    "    dt.fit(train_data, train_target)\n",
    "\n",
    "    test_data = data[test_indices]\n",
    "    test_target = target[test_indices]\n",
    "    \n",
    "    test_prediction = dt.predict(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0a4d50",
   "metadata": {},
   "source": [
    "## Pipelines\n",
    "\n",
    "A [pipeline](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html) in scikit-learn allows you to specify a sequence of transforms and a final estimator that can be executed and cross-validated.\n",
    "This way you don't have to worry about applying the preprocessing steps (transforms) properly to each training and test split.\n",
    "\n",
    "You create a pipeline by defining the steps that should be executed as a list.\n",
    "Each element of the list is a tuple that consists of a name and the transform or estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3cb27199",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy = 95.33333333333334%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "transform = StandardScaler()\n",
    "estimator = KNeighborsClassifier()\n",
    "\n",
    "pipeline = Pipeline([ ('normalisation', transform), ('classification', estimator) ])\n",
    "\n",
    "accuracy_iris = cross_val_score(pipeline, iris_data, iris_target, cv=10, scoring='accuracy')\n",
    "\n",
    "print(\"Average Accuracy = {}%\".format(accuracy_iris.mean() * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c91cf1",
   "metadata": {},
   "source": [
    "# Intermezzo: Hyperparameter Optimization\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"imgs/hpo_meme.jpg\" style=\"width: 50%;\">\n",
    "</div>\n",
    "\n",
    "\n",
    "## Hyperparameter Selection\n",
    "\n",
    "**Hyperparameter**: a parameter which influences the learning process and whose value is **set before the learning begins** (e.g., learning rate, number of hidden layers for ANNs, pruning thresholds for decision trees, $K$ for K-NN)\n",
    "\n",
    "**Parameter**: the values learned by an estimator during training / from the training data (e.g., weights in ANN, splits in a tree)\n",
    "\n",
    "### üõ†  The complete learning procedure is thus:\n",
    "- Hyperparameter Tuning ‚û°Ô∏è pick best hyperparameters\n",
    "- Training ‚û°Ô∏è find best parameters\n",
    "- Testing model performance on *unseen* test data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00763db8",
   "metadata": {},
   "source": [
    "**Goal of Hyperparameter Optimization**: find the combination of hyperparameter values that result in learning the model with the lowest generalization error\n",
    "\n",
    "## Search Strategies\n",
    "\n",
    "### 1. Brute Force Search\n",
    "- Try out all hyperparameter combinations \n",
    "- Computationally impossible; ‚Äúblind‚Äù evaluation of parameters\n",
    "\n",
    "### 2. Grid Search\n",
    "- Manually restrict search space to certain parameter combinations\n",
    "- Quality of solution strongly dependent on grid definition\n",
    "- It may miss the best parameters\n",
    "\n",
    "\n",
    "### 3. Random Search\n",
    "- Test all combinations of random parameter values\n",
    "\n",
    "\n",
    "### 4. Bayesian Optimization\n",
    "- Treat hyperparameter tuning as a learning problem:\n",
    "    - Given a set of hyperparameters $p$, predict the evaluation score $s$ of the model\n",
    "    - The prediction model is called a **surrogate model** or **oracle**\n",
    "- Why? Because training and evaluating the actual model is costly\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"imgs/bayesian_optimization.png\" style=\"width: 60%;\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b1daf9",
   "metadata": {},
   "source": [
    "### Grid Search in Python\n",
    "\n",
    "- We perform the hyper-parameter tuning using [Grid Search](http://scikit-learn.org/stable/modules/grid_search.html).\n",
    "- It is implemented in the [```GridSearchCV``` class](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) in scikit-learn.\n",
    "- This class behaves exactly like an estimator. If its ```fit()``` function is called, all hyper-parameter combinations are evaluated.\n",
    "\n",
    "Parameters:\n",
    "- ```estimator```: an estimator (e.g. a decision tree)\n",
    "- ```parameter_grid```: the parameters that should be evaluated as a dictionary\n",
    "    - the key is the name of the hyper-parameter\n",
    "    - the value is a list of possible values\n",
    "    - example: ```{'param_a':[1,2,3], 'param_b':[7,8,9] }```\n",
    "- ```scoring```: the metric that should be used to evaluate the parameter settings (can be 'accuracy' or other scores)\n",
    "- ```cv```: specifies how to perform cross validation (default: 3-fold cross validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "41b0bc72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_n_neighbors</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001524</td>\n",
       "      <td>0.000244</td>\n",
       "      <td>0.002633</td>\n",
       "      <td>0.000234</td>\n",
       "      <td>2</td>\n",
       "      <td>{'n_neighbors': 2}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.946667</td>\n",
       "      <td>0.058119</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001173</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>0.002231</td>\n",
       "      <td>0.000242</td>\n",
       "      <td>3</td>\n",
       "      <td>{'n_neighbors': 3}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.053333</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001230</td>\n",
       "      <td>0.000123</td>\n",
       "      <td>0.002332</td>\n",
       "      <td>0.000335</td>\n",
       "      <td>4</td>\n",
       "      <td>{'n_neighbors': 4}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.053333</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001237</td>\n",
       "      <td>0.000166</td>\n",
       "      <td>0.002275</td>\n",
       "      <td>0.000270</td>\n",
       "      <td>5</td>\n",
       "      <td>{'n_neighbors': 5}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.953333</td>\n",
       "      <td>0.052068</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001262</td>\n",
       "      <td>0.000187</td>\n",
       "      <td>0.002619</td>\n",
       "      <td>0.001158</td>\n",
       "      <td>6</td>\n",
       "      <td>{'n_neighbors': 6}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.001200</td>\n",
       "      <td>0.000142</td>\n",
       "      <td>0.002233</td>\n",
       "      <td>0.000171</td>\n",
       "      <td>7</td>\n",
       "      <td>{'n_neighbors': 7}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.973333</td>\n",
       "      <td>0.032660</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.001219</td>\n",
       "      <td>0.000129</td>\n",
       "      <td>0.002265</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>8</td>\n",
       "      <td>{'n_neighbors': 8}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.032660</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       0.001524      0.000244         0.002633        0.000234   \n",
       "1       0.001173      0.000094         0.002231        0.000242   \n",
       "2       0.001230      0.000123         0.002332        0.000335   \n",
       "3       0.001237      0.000166         0.002275        0.000270   \n",
       "4       0.001262      0.000187         0.002619        0.001158   \n",
       "5       0.001200      0.000142         0.002233        0.000171   \n",
       "6       0.001219      0.000129         0.002265        0.000194   \n",
       "\n",
       "   param_n_neighbors              params  split0_test_score  \\\n",
       "0                  2  {'n_neighbors': 2}                1.0   \n",
       "1                  3  {'n_neighbors': 3}                1.0   \n",
       "2                  4  {'n_neighbors': 4}                1.0   \n",
       "3                  5  {'n_neighbors': 5}                1.0   \n",
       "4                  6  {'n_neighbors': 6}                1.0   \n",
       "5                  7  {'n_neighbors': 7}                1.0   \n",
       "6                  8  {'n_neighbors': 8}                1.0   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "0           0.933333                1.0           0.933333           0.866667   \n",
       "1           1.000000                1.0           0.933333           0.866667   \n",
       "2           1.000000                1.0           0.933333           0.866667   \n",
       "3           1.000000                1.0           0.933333           0.866667   \n",
       "4           1.000000                1.0           0.933333           0.933333   \n",
       "5           1.000000                1.0           0.933333           0.933333   \n",
       "6           0.933333                1.0           0.933333           0.933333   \n",
       "\n",
       "   split5_test_score  split6_test_score  split7_test_score  split8_test_score  \\\n",
       "0           0.866667                1.0                1.0           1.000000   \n",
       "1           0.866667                1.0                1.0           1.000000   \n",
       "2           0.866667                1.0                1.0           1.000000   \n",
       "3           0.866667                1.0                1.0           0.933333   \n",
       "4           0.933333                1.0                1.0           0.933333   \n",
       "5           0.933333                1.0                1.0           0.933333   \n",
       "6           0.933333                1.0                1.0           0.933333   \n",
       "\n",
       "   split9_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0           0.866667         0.946667        0.058119                7  \n",
       "1           0.933333         0.960000        0.053333                3  \n",
       "2           0.933333         0.960000        0.053333                3  \n",
       "3           0.933333         0.953333        0.052068                6  \n",
       "4           0.933333         0.966667        0.033333                2  \n",
       "5           1.000000         0.973333        0.032660                1  \n",
       "6           0.933333         0.960000        0.032660                5  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score is 0.9733333333333334 with params {'n_neighbors': 7}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# create an estimator\n",
    "knn_estimator = KNeighborsClassifier()\n",
    "\n",
    "# specify the parameter grid\n",
    "parameters = {\n",
    "    'n_neighbors': range(2, 9)\n",
    "}\n",
    "\n",
    "# specify the cross validation\n",
    "stratified_10_fold_cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# create the grid search instance\n",
    "grid_search_estimator = GridSearchCV(\n",
    "    knn_estimator, \n",
    "    parameters, \n",
    "    scoring='accuracy', \n",
    "    cv=stratified_10_fold_cv, \n",
    "    return_train_score=False\n",
    ")\n",
    "\n",
    "# run the grid search\n",
    "grid_search_estimator.fit(iris_data,iris_target)\n",
    "\n",
    "# print the results of all hyper-parameter combinations\n",
    "results = pd.DataFrame(grid_search_estimator.cv_results_)\n",
    "display(results)\n",
    "    \n",
    "# print the best parameter setting\n",
    "print(\"best score is {} with params {}\".format(\n",
    "    grid_search_estimator.best_score_, grid_search_estimator.best_params_)\n",
    "     )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "305e07e9",
   "metadata": {},
   "source": [
    "## Model Selection\n",
    "\n",
    "**Goal**: Select the model $m_{best}$ from all learned models $M$ that is expected to generalize best to unseen records\n",
    "\n",
    "## ‚ö†Ô∏è Separate data for model selection from the data for model evaluation!\n",
    "\n",
    "Otherwise: \n",
    "- overfitting to test set\n",
    "- overly optimistic generalization error estimate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be91f90",
   "metadata": {},
   "source": [
    "## Model Selection using a Validation Set\n",
    "\n",
    "1. Split training set $D_{train}$ into validation set $D_{val}$ and training set $D_{tr}$\n",
    "2. Learn models $m_i$ on $D_{tr}$ using different hyperparameter value combinations $p_i$\n",
    "3. Select best parameter values$p_{best}$ by testing each model $m_i$ on the validation set $D_{val}$\n",
    "4. Learn the final model $m_{best}$ on complete $D_{train}$ using the parameter values $p_{best}$\n",
    "5. Evaluate $m_{best}$ on test set in order to get a unbiased estimate of its generalization performance\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"imgs/model_selection_val_set.png\" style=\"width: 40%;\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8644c28",
   "metadata": {},
   "source": [
    "## Model Selection using a Cross-Validation \n",
    "\n",
    "‚úÖ Make sure that all examples are used for validation once\n",
    "\n",
    "‚úÖ Use as much labeled data as possible for training\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"imgs/model_selection_crossval.png\" style=\"width: 70%;\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11dea144",
   "metadata": {},
   "source": [
    "# Back to Evaluation Methods\n",
    "\n",
    "## Nested Cross-Validation\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"imgs/model_selection_nested_crossval.png\" style=\"width: 70%;\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e521077",
   "metadata": {},
   "source": [
    "### Nested Cross-Validation in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3a762b6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.9666666666666668)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': 7}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# use only 5 folds here, as we only have 50 examples per class in the iris dataset!\n",
    "nested_cv_score = cross_val_score(grid_search_estimator, iris_data, iris_target, cv=5, scoring='accuracy')\n",
    "\n",
    "display(nested_cv_score.mean())\n",
    "\n",
    "grid_search_estimator.fit(iris_data,iris_target)\n",
    "display(grid_search_estimator.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a6024f",
   "metadata": {},
   "source": [
    "### Grid Search using Pipelines\n",
    "\n",
    "Often, we need preprocessing steps before we perform a grid search, or even want to optimise the hyper-parameters of our preprocessing steps.\n",
    "In these cases, we set up a pipeline and run the grid search on all steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "19965c2f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 97.33333333333334%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'classification__n_neighbors': 5,\n",
       " 'normalisation__with_mean': True,\n",
       " 'normalisation__with_std': False}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# create the pipeline\n",
    "transform = StandardScaler()\n",
    "estimator = KNeighborsClassifier()\n",
    "pipeline = Pipeline(steps=[ ('normalisation', transform), ('classification', estimator) ])\n",
    "\n",
    "\n",
    "# specify the parameter grid\n",
    "parameters = {\n",
    "    'normalisation__with_mean': [ True, False],\n",
    "    'normalisation__with_std': [ True, False],\n",
    "    'classification__n_neighbors': range(2, 9)\n",
    "}\n",
    "\n",
    "# create the grid search instance\n",
    "grid_search_estimator = GridSearchCV(pipeline, parameters, scoring='accuracy', cv=10)\n",
    "\n",
    "accuracy_best = cross_val_score(grid_search_estimator, iris_data, iris_target, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "print(\"Accuracy = {}%\".format(accuracy_best.mean() * 100.0))\n",
    "\n",
    "grid_search_estimator.fit(iris_data, iris_target)\n",
    "display(grid_search_estimator.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c0e06ce",
   "metadata": {},
   "source": [
    "# Comparing Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91915ecb",
   "metadata": {},
   "source": [
    "## 1. Confidence Intervals\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"imgs/confidence_intervals_1.png\" style=\"width: 70%;\">\n",
    "</div>\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"imgs/confidence_intervals_2.png\" style=\"width: 70%;\">\n",
    "</div>\n",
    "\n",
    "<span style=\"color:red\">Caution: only for sample size > 30.</span>\n",
    "\n",
    "With p% probability, $error_D$ is in $[error_s - y, error_s + y]$, with $y = z_N \\cdot \\sqrt{\\frac{error_s (1 -error_s)}{n}}$\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"imgs/z_table.png\" style=\"width: 50%;\">\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad1d0676",
   "metadata": {},
   "source": [
    "### Computing Confidence Intervals\n",
    "\n",
    "You are using a machine learning solution from company A. Recently, you were contacted by the Junior Vice President of company B and he offered you to switch to his solution. As a migration is very costly, you only want to switch if you can be at least 90% sure that the new solution is better. For such purposes, you have a dedicated test set with 420 examples where your current solution makes 105 errors. \n",
    "\n",
    "What is the highest number of errors that you accept for the new solution in order to switch?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "263dfc61",
   "metadata": {},
   "source": [
    "#### Solution:\n",
    "\n",
    "|S| =  420 (>30 so we can use the z-test!)\n",
    "\n",
    "$error_S = 0.25$\n",
    "\n",
    "$z_N = 1.64$\n",
    "\n",
    "$y = z_N \\cdot \\sqrt{\\frac{error_s (1 -error_s)}{n}} = 1.64 \\cdot \\sqrt{\\frac{0.25 (1-0.25)}{420}} = 1.64 \\cdot 0.02 = 0.033$\n",
    "\n",
    "- With 90% probability, $error_D$ is in [0.217; 0.283]\n",
    "\n",
    "- The maximum number of errors for the new solution is 0.217 * 420 - 1 = 90"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b96b30",
   "metadata": {},
   "source": [
    "## 2. Statistical Tests: Sign Test vs. Wilcoxon Signed-Rank Test\n",
    "\n",
    "Let's consider two classifiers, $ A $  and $  B$ , evaluated on 12 test instances. We record their accuracy (or any performance metric):\n",
    "\n",
    "| Instance | Model A Score | Model B Score | Difference ($d$) | Sign |\n",
    "|----------|--------------|--------------|----------------|------|\n",
    "| 1        | 0.90         | 0.80         | **+0.10**      | +    |\n",
    "| 2        | 0.88         | 0.75         | **+0.13**      | +    |\n",
    "| 3        | 0.85         | 0.85         | **0.00**       | Tie  |\n",
    "| 4        | 0.92         | 0.88         | **+0.04**      | +    |\n",
    "| 5        | 0.80         | 0.78         | **+0.02**      | +    |\n",
    "| 6        | 0.89         | 0.82         | **+0.07**      | +    |\n",
    "| 7        | 0.91         | 0.84         | **+0.07**      | +    |\n",
    "| 8        | 0.87         | 0.86         | **+0.01**      | +    |\n",
    "| 9        | 0.76         | 0.79         | **‚àí0.03**      | ‚àí    |\n",
    "| 10       | 0.93         | 0.85         | **+0.08**      | +    |\n",
    "| 11       | 0.95         | 0.88         | **+0.07**      | +    |\n",
    "| 12       | 0.89         | 0.82         | **+0.07**      | +    |\n",
    "\n",
    "- **+** means Model A outperformed Model B.  \n",
    "- **‚àí** means Model B outperformed Model A.  \n",
    "- **Ties are removed.**  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce9e5c4",
   "metadata": {},
   "source": [
    "### Sign Test\n",
    "\n",
    "The **Sign Test** only considers the number of wins/losses. The null hypothesis ($H_0$) assumes that Model A and Model B are equally good, meaning that each instance is equally likely to favor either model ($p = 0.5$).\n",
    "\n",
    "**Step 1: Count the wins**\n",
    "\n",
    "Ignoring the tie (Instance 3):\n",
    "- **Model A wins:** $n_A = 10$ \n",
    "- **Model B wins:** $n_B = 1$  \n",
    "- **Ties:** $n_t = 1$  \n",
    "- **Total non-tied instances:** $n' = 11$ \n",
    "\n",
    "**Step 2: Find the critical value**\n",
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"imgs/sign_test_table.png\" style=\"width: 60%;\">\n",
    "</div>\n",
    "\n",
    "Since Model A performs better than Model B in 10 cases, we **reject \\( H_0 \\)** ‚Üí **Model A is significantly better than Model B.** ‚úÖ  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4045e91",
   "metadata": {},
   "source": [
    "### Wilcoxon Signed-Rank Test\n",
    "\n",
    "The **Wilcoxon signed-rank test** considers both **signs** and **magnitude** of the differences.\n",
    "\n",
    "**Step 1: Rank results by _absolute differences_**\n",
    "- Ties are ignored\n",
    "- Equal ranks are averaged\n",
    "\n",
    "| Instance | Model A Score | Model B Score | Difference ($d$) | Absolute $d$ | Rank |\n",
    "|----------|--------------|--------------|----------------|----------------|------|\n",
    "| 1        | 0.90         | 0.80         | **+0.10**      | 0.10           | **10**  |\n",
    "| 2        | 0.88         | 0.75         | **+0.13**      | 0.13           | **11**  |\n",
    "| 3        | 0.85         | 0.85         | **0.00**       | 0.00           | **Tie**  |\n",
    "| 4        | 0.92         | 0.88         | **+0.04**      | 0.04           | **4**  |\n",
    "| 5        | 0.80         | 0.78         | **+0.02**      | 0.02           | **2**  |\n",
    "| 6        | 0.89         | 0.82         | **+0.07**      | 0.07           | **7**  |\n",
    "| 7        | 0.91         | 0.84         | **+0.07**      | 0.07           | **7**  |\n",
    "| 8        | 0.87         | 0.86         | **+0.01**      | 0.01           | **1**  |\n",
    "| 9        | 0.76         | 0.79         | **‚àí0.03**      | 0.03           | **3**  |\n",
    "| 10       | 0.93         | 0.85         | **+0.08**      | 0.08           | **9**  |\n",
    "| 11       | 0.95         | 0.88         | **+0.07**      | 0.07           | **7**  |\n",
    "| 12       | 0.89         | 0.82         | **+0.07**      | 0.07           | **7**  |\n",
    "\n",
    "**Step 2: Sum ranks by sign**\n",
    "- **Sum of positive ranks**: $W_+ = 10 + 11 + 4 + 2 + 7 + 7 + 1 + 9 + 7 + 7 = 65$\n",
    " \n",
    "- **Sum of negative ranks**: $W_- = 3$\n",
    "\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"imgs/wilcoxon_signed_test_table.png\" style=\"width: 60%;\">\n",
    "</div>\n",
    "\n",
    "**Step 3: Compute the test statistic \\( W \\)**\n",
    "\n",
    "Wilcoxon‚Äôs statistic is the smaller sum of ranks:  \n",
    "$W = \\min(W_+, W_-) = \\min(65, 3) = 3$\n",
    "\n",
    "**Step 4: Find the critical value**\n",
    "\n",
    "Since $W = 3 < 13$, **we reject $H_0$** ‚Üí **Model A is significantly better than Model B.** ‚úÖ  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15fb9baf",
   "metadata": {},
   "source": [
    "# QUIZ TIME"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51cfe04e",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "\n",
    "You train a Na√Øve Bayes classifier for sentiment analysis on movie reviews. The model predicts **positive sentiment** for the review:\n",
    "\n",
    "_\"The movie was absolutely amazing, the plot was thrilling, but the acting was mediocre.\"_\n",
    "\n",
    "The words \"amazing\" and \"thrilling\" are associated with **positive** sentiment, while \"mediocre\" is linked to **negative** sentiment. Why might Na√Øve Bayes still classify this as **positive**?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea6ac84",
   "metadata": {},
   "source": [
    "### Solution:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac0afaca",
   "metadata": {},
   "source": [
    "Na√Øve Bayes makes decisions by multiplying probabilities of words independently. If **\"amazing\"** and **\"thrilling\"** have high conditional probabilities under the positive class, their contributions might outweigh the negative contribution of **\"mediocre\"**.\n",
    "\n",
    "Since multiplication amplifies large differences (e.g., 0.7 √ó 0.8 vs. 0.1), a few strongly positive words can dominate over one weakly negative word. This shows a limitation of Na√Øve Bayes: **it does not consider interactions between words** (e.g., \"thrilling but mediocre\" might indicate mixed sentiment, which Na√Øve Bayes ignores)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e247432",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "\n",
    "Table below contains information about different biological species. Using the training data, create a Naive\n",
    "Bayes classification model and classify the following examples:\n",
    "- Dolphin <yes, no, yes, no>\n",
    "- Duck <no, yes, sometimes, yes>\n",
    "\n",
    "| Gives birth | Can fly | Lives in Water | Has Legs | Class       |\n",
    "| ----------- | ------- | -------------- | -------- | ----------- |\n",
    "| yes         | no      | no             | yes      | mammals     |\n",
    "| no          | no      | no             | no       | non-mammals |\n",
    "| no          | no      | yes            | no       | non-mammals |\n",
    "| yes         | no      | yes            | no       | mammals     |\n",
    "| no          | no      | sometimes      | yes      | non-mammals |\n",
    "| no          | no      | no             | yes      | non-mammals |\n",
    "| yes         | yes     | no             | yes      | mammals     |\n",
    "| no          | yes     | no             | yes      | non-mammals |\n",
    "| yes         | no      | no             | yes      | mammals     |\n",
    "| yes         | no      | yes            | no       | non-mammals |\n",
    "| no          | no      | sometimes      | yes      | non-mammals |\n",
    "| no          | no      | sometimes      | yes      | non-mammals |\n",
    "| yes         | no      | no             | yes      | mammals     |\n",
    "| no          | no      | yes            | no       | non-mammals |\n",
    "| no          | no      | sometimes      | yes      | non-mammals |\n",
    "| no          | no      | no             | yes      | non-mammals |\n",
    "| no          | no      | no             | yes      | mammals     |\n",
    "| no          | yes     | no             | yes      | non-mammals |\n",
    "| yes         | no      | yes            | no       | mammals     |\n",
    "| no          | yes     | no             | yes      | non-mammals |\n",
    "\n",
    "Steps:\n",
    "1. Compute the prior probability of each class\n",
    "2. Compute the class conditional probability of evidence (for each attribute)\n",
    "3. Classify the _Dolphin_ and _Duck_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73fc40c3",
   "metadata": {},
   "source": [
    "### Solution:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae7d0ba2",
   "metadata": {},
   "source": [
    "#### 1. Compute the prior probability of each class\n",
    "\n",
    "We have **2 classes**: _Mammals_ and _Non-mammals_\n",
    "\n",
    "- $P(Mammals) = \\frac{7}{20}$\n",
    "- $P(Non-mammals) = \\frac{13}{20}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b96cfdba",
   "metadata": {},
   "source": [
    "#### 2. Compute the class conditional probability of evidence (for each attribute)\n",
    "\n",
    "There are four attributes:\n",
    "\n",
    "- Gives birth:\n",
    "    - $P(yes | Mammals) = \\frac{6}{7}$\n",
    "    - $P(no | Mammals) = \\frac{1}{7}$\n",
    "    - $P(yes | Non-mammals) = \\frac{1}{13}$\n",
    "    - $P(no | Non-mammals) = \\frac{12}{13}$\n",
    "- Can fly:\n",
    "    - $P(yes | Mammals) = \\frac{1}{7}$\n",
    "    - $P(no | Mammals) = \\frac{6}{7}$\n",
    "    - $P(yes | Non-mammals) = \\frac{3}{13}$\n",
    "    - $P(no | Non-mammals) = \\frac{10}{13}$\n",
    "- Lives in Water:\n",
    "    - $P(yes | Mammals) = \\frac{2}{7}$\n",
    "    - $P(no | Mammals) = \\frac{5}{7}$\n",
    "    - $P(sometimes | Mammals) = \\frac{0}{7}$\n",
    "    - $P(yes | Non-mammals) = \\frac{3}{13}$\n",
    "    - $P(no | Non-mammals) = \\frac{6}{13}$ \n",
    "    - $P(sometimes | Non-mammals) = \\frac{4}{13}$ \n",
    "- Has Legs:\n",
    "    - $P(yes | Mammals) = \\frac{5}{7}$\n",
    "    - $P(no | Mammals) = \\frac{2}{7}$\n",
    "    - $P(yes | Non-mammals) = \\frac{9}{13}$\n",
    "    - $P(no | Non-mammals) = \\frac{4}{13}$ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef6de50",
   "metadata": {},
   "source": [
    "#### 3. Classify the given examples\n",
    "\n",
    "##### Dolphin\n",
    "P(Mammals | Dolphin) \n",
    "\n",
    "= $\\frac{\\text{P(Gives birth=yes | Mammals) * P(Can fly=no | Mammals) * P(Lives in Water=yes | Mammals) * P(Has Legs=no | Mammals) * P(Mammals)}}{ P(Dolphin)}$\n",
    "\n",
    "$\\equiv \\frac{6}{7} * \\frac{6}{7} * \\frac{2}{7} * \\frac{2}{7} * \\frac{7}{20} = 0.021$ \n",
    "\n",
    "*--> **NOTE**: we write P(Dolphin) for completeness but we do not actually compute it. As explained above, the probability of evidence P(Dolphin) appears in the denominator of both P(Mammals | Dolphin)  and P(Non-Mammals | Dolphin), so it does not influence which one is bigger. We do the same for all the examples below*\n",
    "\n",
    "----\n",
    "P(Non-Mammals | Dolphin) \n",
    "\n",
    "= $\\frac{\\text{P(Gives birth=yes | Non-Mammals) * P(Can fly=no | Non-Mammals) * P(Lives in Water=yes | Non-Mammals) * P(Has Legs=no | Non-Mammals) * P(Non-Mammals)}}{P(Dolphin)}$\n",
    "\n",
    "$\\equiv \\frac{1}{13} * \\frac{10}{13} * \\frac{3}{13} * \\frac{4}{13} * \\frac{13}{20} = 0.0027$ \n",
    "\n",
    "----\n",
    "**Decision**: P(Mammals | Dolphin) > P(Non-Mammals | Dolphin) => **Dolphin: class Mammals**\n",
    "\n",
    "##### Duck:\n",
    "\n",
    "P(Mammals | Duck) \n",
    "\n",
    "= P(Gives birth=no | Mammals) * P(Can fly=yes | Mammals) * P(Lives in Water=sometimes | Mammals) * P(Has Legs=yes | Mammals) * P(Mammals) / P(Duck)\n",
    "\n",
    "$\\equiv \\frac{1}{7} * \\frac{1}{7} * \\frac{0}{7} * \\frac{5}{7} * \\frac{7}{20} = 0$ \n",
    "\n",
    "----\n",
    "P(Non-Mammals | Duck) \n",
    "\n",
    "= P(Gives birth=no | Non-Mammals) * P(Can fly=yes | Non-Mammals) * P(Lives in Water=sometimes | Non-Mammals) * P(Has Legs=yes | Non-Mammals) * P(Non-Mammals) / P(Duck)\n",
    "\n",
    "$\\equiv \\frac{12}{13} * \\frac{3}{13} * \\frac{4}{13} * \\frac{9}{13} * \\frac{13}{20} = 0.0295$ \n",
    "\n",
    "----\n",
    "**Decision**: P(Mammals | Duck) < P(Non-Mammals | Duck) $ => **Duck: class Non-Mammals**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce607884",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "\n",
    "Suppose you are using the **holdout method** to evaluate a machine learning model. You split your dataset into **70% training** and **30% testing**. You then perform **feature selection** on the **entire dataset** before training the model.\n",
    "\n",
    "Why is this a problem?\n",
    "How would this affect the model‚Äôs performance on new, unseen data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "874ac6ac",
   "metadata": {},
   "source": [
    "### Solution:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a52588e",
   "metadata": {},
   "source": [
    "- The problem is **data leakage**: performing feature selection on the entire dataset means that **information from the test set influences the training process**.\n",
    "- This will result in an **overoptimistic evaluation** because the test set is no longer truly unseen‚Äîit has influenced the feature selection step.\n",
    "- In real-world deployment, new data won‚Äôt have this prior knowledge, leading to **poor generalization**.\n",
    "- Correct approach: Perform feature selection **only on the training set** (e.g., inside cross-validation folds)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b25c1cf",
   "metadata": {},
   "source": [
    "## Question 4\n",
    "\n",
    "A researcher performs **10-fold cross-validation** for **hyperparameter tuning** and then trains the final model on the entire dataset. They **evaluate this final model using another round of 10-fold cross-validation on the same dataset**.\n",
    "\n",
    "- Why is this evaluation flawed?\n",
    "- How should the researcher evaluate the final model properly?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "449036ff",
   "metadata": {},
   "source": [
    "### Solution:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b0ebf6",
   "metadata": {},
   "source": [
    "- The mistake is **evaluating on the same data used for hyperparameter tuning**. This **leads to overfitting**, because the best hyperparameters were selected based on those 10 folds.\n",
    "- The second round of cross-validation is **not truly independent**; it is **biased toward hyperparameters that performed well on that dataset**, leading to **overestimated performance**.\n",
    "- Correct approach: Use **nested cross-validation**, where an **outer cross-validation loop** evaluates generalization performance, and an **inner loop** performs hyperparameter tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1de38af",
   "metadata": {},
   "source": [
    "## Question 5\n",
    "\n",
    "Cross-validation is often preferred over the holdout method since it provides a more reliable estimate of generalization performance.\n",
    "\n",
    "In what scenarios might the **holdout method** be preferable to **cross-validation**?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa923d4",
   "metadata": {},
   "source": [
    "### Solution:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "349277e2",
   "metadata": {},
   "source": [
    "- **When computational cost is high**: Cross-validation requires training multiple models, which is expensive for large datasets or deep learning models.\n",
    "- **When dataset is extremely large**: If we have millions of samples, a well-stratified holdout set can provide a reliable estimate without needing multiple splits.\n",
    "- **When hyperparameter tuning is minimal**: If hyperparameter tuning is not extensive, a single holdout set might be sufficient.\n",
    "- **For online learning / real-time applications**: When new data arrives continuously, re-training models with cross-validation is impractical. A simple train-test split might be more feasible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7b9c88",
   "metadata": {},
   "source": [
    "## Question / Task 6\n",
    "\n",
    "This exercise is about hyperparameter tuning. To get familiar with hyperparameter tuning in scikit-learn, refer to the respective [part in the documentation](https://scikit-learn.org/stable/modules/grid_search.html).\n",
    "\n",
    "We will use the data set of the Data Mining Cup 2006, which you can find in **data/dmc2006**. The task is to predict the attribute `gms_greater_avg` as precisely as possible. We will use the F1-measure of the class `1` as main performance metric.\n",
    "\n",
    "1. Data preparation.\n",
    "    - Import the data and create a 50:50 train-test split.\n",
    "    - Implement the `evaluate_estimators` function so that it returns precision, recall, and F1-measure of the class 1 on the test set for the classifiers given in `estimators`. Use the following `estimators`: {Naive Bayes, K-NN, SVC}\n",
    "\n",
    "2. Grid Search\n",
    "    - Run a grid search with the parameters given in `tune_params` with F1-measure as optimization objective. \n",
    "    \n",
    "    ```python\n",
    "    tune_params = {\n",
    "    \n",
    "        'K-NN': {\n",
    "            'n_neighbors': [1, 3, 5, 10]\n",
    "        },\n",
    "        \n",
    "        'SVC': {\n",
    "            'C': [.001, .01, .1, 1, 10, 100],\n",
    "            'gamma': ['scale', 'auto'],\n",
    "            'tol': [1e-2, 1e-3, 1e-4],\n",
    "            'class_weight': ['balanced', None],\n",
    "        }\n",
    "    }\n",
    "    ```\n",
    "    \n",
    "    - For the best estimator, print the parameters and evaluate it with the `evaluate_estimators` function.\n",
    "    \n",
    "    **HINT**: Take a look at https://scikit-learn.org/stable/modules/grid_search.html for infos about grid search.\n",
    "    \n",
    "3. Bayesian Optimization\n",
    "    - Now run a bayesian search with the parameters given in `bayes_tune_params` with F1-measure as objective. Use a `n_iter` of 15.\n",
    "    - Again, print parameters of the best estimator and evaluate it with the `evaluate_estimators` function.\n",
    "\n",
    "    **HINT**: Use scikit-optimize for bayesian search (https://scikit-optimize.github.io/stable/auto_examples/bayesian-optimization.html)\n",
    "\n",
    "    **HINT**: Currently, BayesSearchCV does not work with scikit-learn version of 0.24.1. Use version 0.23.2 instead      -> run a cell with `!pip install scikit-learn==0.23.2` and restart the notebook.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa4792e",
   "metadata": {},
   "source": [
    "### Solution:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa88fa5",
   "metadata": {},
   "source": [
    "#### 1. Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8c17780d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes: P=0.63 R=0.29 F1=0.39\n",
      "K-NN: P=0.60 R=0.59 F1=0.60\n",
      "SVC: P=0.63 R=0.29 F1=0.40\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "RANDOM_STATE = 42  # use this random state to make your experiments consistent\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "# Use the pandas library to import the training data.\n",
    "df = pd.read_csv('data/dmc2006/dmc2006_train.txt', sep='\\t', encoding='cp1252').drop(columns=['auct_id', 'gms', 'listing_title', 'listing_subtitle', 'listing_start_date', 'listing_end_date'])\n",
    "X, y = df.drop(columns='gms_greater_avg'), df['gms_greater_avg']\n",
    "\n",
    "# converting columns to have reasonable format\n",
    "X = pd.get_dummies(X, columns=['item_leaf_category_name'])\n",
    "boolean_columns = [k for k, v in X.dtypes.items() if v == np.object_]\n",
    "X[boolean_columns] = X[boolean_columns].apply(lambda row: [1 if x == 'Y' else 0 for x in row])\n",
    "\n",
    "# Create a 50:50 train-test-split and assign the results to the variables X_train, X_test and y_train, y_test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.5, random_state=RANDOM_STATE, stratify=y)\n",
    "\n",
    "# Instantiate the estimators\n",
    "estimators = {\n",
    "    'Naive Bayes': GaussianNB().fit(X_train, y_train),\n",
    "    'K-NN': KNeighborsClassifier(n_neighbors=1).fit(X_train, y_train),\n",
    "    'SVC': SVC(random_state=RANDOM_STATE).fit(X_train, y_train)\n",
    "}\n",
    "\n",
    "# Implement the `evaluate_estimators` function so that it returns precision, recall, and F1-measure\n",
    "# of the class 1 on the test set for the classifiers given in `estimators`.\n",
    "\n",
    "def evaluate_estimators(estimators, X, y_true):\n",
    "    for e_name, e in estimators.items():\n",
    "        p, r, f1, _ = precision_recall_fscore_support(y_true, e.predict(X), average='binary')\n",
    "        print(f'{e_name}: P={p:.2f} R={r:.2f} F1={f1:.2f}')\n",
    "        \n",
    "        \n",
    "evaluate_estimators(estimators, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc743d5",
   "metadata": {},
   "source": [
    "#### 2. Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "82d6da5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-NN best parameters: {'n_neighbors': 3}\n",
      "SVC best parameters: {'C': 1, 'class_weight': 'balanced', 'gamma': 'auto', 'tol': 0.01}\n",
      "K-NN: P=0.60 R=0.57 F1=0.59\n",
      "SVC: P=0.55 R=0.67 F1=0.61\n",
      "CPU times: user 8min 9s, sys: 6.09 s, total: 8min 15s\n",
      "Wall time: 8min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "tune_params = {\n",
    "    'K-NN': {\n",
    "        'n_neighbors': [1, 3, 5, 10]\n",
    "    },\n",
    "    'SVC': {\n",
    "        'C': [.001, .01, .1, 1, 10, 100],\n",
    "        'gamma': ['scale', 'auto'],\n",
    "        'tol': [1e-2, 1e-3, 1e-4],\n",
    "        'class_weight': ['balanced', None],\n",
    "    }\n",
    "}\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def grid_search_estimator(e_name, e, param_grid, X, y):\n",
    "    gscv = GridSearchCV(e, param_grid, scoring='f1', cv=10).fit(X, y)\n",
    "    print(f'{e_name} best parameters: {gscv.best_params_}')\n",
    "    return gscv.best_estimator_\n",
    "\n",
    "grid_estimators = {e_name: grid_search_estimator(e_name, e, tune_params[e_name], X_train, y_train)\n",
    "                   for e_name, e in estimators.items()\n",
    "                   if e_name in tune_params}\n",
    "\n",
    "evaluate_estimators(grid_estimators, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d43a024d",
   "metadata": {},
   "source": [
    "#### 3. Bayesian Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9bcf662c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'skopt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:13\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'skopt'"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "bayes_tune_params = {\n",
    "    'K-NN': {\n",
    "        'n_neighbors': (1, 10)\n",
    "    },\n",
    "    'SVC': {\n",
    "        'C': (1e-3, 1e+3, 'log-uniform'),\n",
    "        'gamma': ['scale', 'auto'],\n",
    "        'tol': (1e-4, 1e-2, 'log-uniform'),\n",
    "        'class_weight': ['balanced', None],\n",
    "    }\n",
    "}\n",
    "\n",
    "from skopt import BayesSearchCV\n",
    "\n",
    "# hint: install scikit-optimize first\n",
    "# hint: use sklearn==0.23.2 and restart notebook after installation\n",
    "def bayes_search_estimator(e_name, e, param_grid, X, y):\n",
    "    bscv = BayesSearchCV(e, search_spaces=param_grid, scoring='f1', n_iter=15, cv=10, random_state=RANDOM_STATE).fit(X, y)\n",
    "    print(f'{e_name} best parameters: {bscv.best_params_}')\n",
    "    return bscv.best_estimator_\n",
    "\n",
    "bayes_estimators = {e_name: bayes_search_estimator(e_name, e, bayes_tune_params[e_name], X_train, y_train)\n",
    "                   for e_name, e in estimators.items()\n",
    "                   if e_name in bayes_tune_params}\n",
    "\n",
    "evaluate_estimators(bayes_estimators, X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Data Mining Env",
   "language": "python",
   "name": "dm_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
