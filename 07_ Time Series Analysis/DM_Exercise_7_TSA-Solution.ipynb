{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the cell below if you are using Google Colab to mount your Google Drive in your Colab instance. Adjust the path to the files in your Google Drive as needed if it differs.\n",
    "\n",
    "If you do not use Google Colab, running the cell will simply do nothing, so do not worry about it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive/')\n",
    "    %cd 'drive/My Drive/Colab Notebooks/06_Regression'\n",
    "except ImportError as e:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install plotly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Let's have a look at some plots to determine how the features (we ignore the dates for now) are related to each other:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output, Audio, HTML\n",
    "import json\n",
    "import os\n",
    "\n",
    "with open(\"questions.json\", \"r\") as file:\n",
    "    questions = json.load(file)\n",
    "\n",
    "random.shuffle(questions)\n",
    "\n",
    "# Lifelines\n",
    "lifelines = {\"50:50\": 2, \"Buddy\": 2}\n",
    "\n",
    "# Game State\n",
    "current_question = 0\n",
    "score = 0\n",
    "lifeline_used = {\"50:50\": False, \"Buddy\": False}  # Track if a lifeline has been used this round\n",
    "\n",
    "output = widgets.Output()\n",
    "progress_label = widgets.Label()\n",
    "question_box = widgets.VBox([])\n",
    "lifeline_box = widgets.VBox([])\n",
    "next_button = widgets.Button(description=\"Next Question\", layout=widgets.Layout(width=\"150px\"))\n",
    "next_button.on_click(lambda btn: next_question())  # Bind function\n",
    "\n",
    "def play_sound(filename):\n",
    "    if os.path.exists(filename):  # Ensure file exists before playing\n",
    "        audio = Audio(filename, autoplay=True)\n",
    "        display(HTML(\"<style>.jp-OutputArea-output audio { display: none; }</style>\"))  # Hide the player\n",
    "        display(audio)  # Display the audio but assign it to `_` to suppress output\n",
    "\n",
    "def ask_question():\n",
    "    \"\"\"Displays a new question when 'Next Question' is clicked.\"\"\"\n",
    "    global current_question, score, lifeline_used\n",
    "    lifeline_used = {\"50:50\": False, \"Buddy\": False}  # Reset lifeline usage per question\n",
    "\n",
    "    if current_question >= len(questions):\n",
    "        with output:\n",
    "            clear_output(wait=True)\n",
    "            print(f\"🎉 Game Over! Your final score: {score}/{len(questions)}\")\n",
    "        return\n",
    "\n",
    "    with output:\n",
    "        clear_output(wait=True)\n",
    "        print(\"Provide your answer.\")\n",
    "\n",
    "    q = questions[current_question]\n",
    "    progress_label.value = f\"🔢 Question {current_question + 1} / {len(questions)}\"\n",
    "\n",
    "    options = q['options'][:]\n",
    "    random.shuffle(options)\n",
    "\n",
    "    buttons = []\n",
    "\n",
    "    def check_answer(btn):\n",
    "        \"\"\"Checks the answer, disables interactions, and shows 'Next Question' button.\"\"\"\n",
    "        global current_question, score, lifeline_used\n",
    "\n",
    "        # Disable answer buttons\n",
    "        for button in buttons:\n",
    "            button.disabled = True\n",
    "\n",
    "        lifeline_used = {\"50:50\": True, \"Buddy\": True}\n",
    "\n",
    "        disable_lifelines()\n",
    "\n",
    "        # Show result\n",
    "        with output:\n",
    "            clear_output(wait=True)\n",
    "            if btn.description == q['answer']:\n",
    "                score += 1\n",
    "                print(\"✅ Correct!\")\n",
    "                play_sound(\"data/correct.mp3\")  # Play sound for correct answer\n",
    "            else:\n",
    "                print(f\"❌ Incorrect. The correct answer was: {q['answer']}\")\n",
    "                play_sound(\"data/incorrect.mp3\")  # Play sound for correct answer\n",
    "\n",
    "        next_button.layout.display = \"block\"  # Show \"Next Question\" button\n",
    "\n",
    "    for option in options:\n",
    "        button = widgets.Button(description=option, layout=widgets.Layout(width='600px'))\n",
    "        button.on_click(check_answer)\n",
    "        buttons.append(button)\n",
    "\n",
    "    question_box.children = [widgets.HBox(\n",
    "        [progress_label, widgets.Label(layout=widgets.Layout(width=\"30px\")), next_button]),\n",
    "                                widgets.Label(q['question'])] + buttons\n",
    "\n",
    "    next_button.layout.display = \"none\"  # Hide the button initially\n",
    "\n",
    "    display_lifeline_buttons()\n",
    "    display(question_box)\n",
    "    display(output)\n",
    "\n",
    "\n",
    "def next_question():\n",
    "    \"\"\"Moves to the next question and clears the previous output.\"\"\"\n",
    "    global current_question\n",
    "    current_question += 1\n",
    "    with output:\n",
    "        clear_output(wait=True)  # Clear result BEFORE new question appears\n",
    "        print(\"Provide your answer.\")\n",
    "    ask_question()  # Load next question\n",
    "\n",
    "\n",
    "def display_lifeline_buttons():\n",
    "    \"\"\"Displays available lifelines as buttons and ensures they are only usable once per question.\"\"\"\n",
    "    lifeline_buttons = []\n",
    "    for lifeline in lifelines:\n",
    "        if lifelines[lifeline] > 0:\n",
    "            icon = \"🔹\" if lifeline == \"50:50\" else \"🧑‍🤝‍🧑\"\n",
    "            button = widgets.Button(description=f\"{icon} {lifeline} ({lifelines[lifeline]} left)\",\n",
    "                                    layout=widgets.Layout(width='200px'))\n",
    "            button.on_click(lambda btn, lf=lifeline: use_lifeline(lf))\n",
    "            lifeline_buttons.append(button)\n",
    "\n",
    "    lifeline_box.children = lifeline_buttons\n",
    "    display(lifeline_box)\n",
    "\n",
    "\n",
    "def use_lifeline(lifeline):\n",
    "    \"\"\"Handles lifeline usage and disables them after one use per question.\"\"\"\n",
    "    global current_question, lifeline_used\n",
    "\n",
    "    if lifelines[lifeline] > 0 and not lifeline_used[lifeline]:\n",
    "        lifelines[lifeline] -= 1\n",
    "        lifeline_used[lifeline] = True  # Prevent another lifeline from being used\n",
    "\n",
    "        with output:\n",
    "            clear_output(wait=True)\n",
    "\n",
    "            if lifeline == \"50:50\":\n",
    "                q = questions[current_question]\n",
    "                incorrect_options = [opt for opt in q['options'] if opt != q['answer']]\n",
    "                removed_options = random.sample(incorrect_options, 2)\n",
    "\n",
    "                new_buttons = []\n",
    "                for button in question_box.children[1:]:\n",
    "                    if button.description in removed_options:\n",
    "                        button.description = \"\"\n",
    "                        button.disabled = True\n",
    "                    new_buttons.append(button)\n",
    "\n",
    "                question_box.children = [widgets.HBox(\n",
    "                    [progress_label, widgets.Label(layout=widgets.Layout(width=\"30px\")), next_button])] + new_buttons\n",
    "\n",
    "            elif lifeline == \"Buddy\":\n",
    "                q = questions[current_question]\n",
    "            play_sound(\"data/joker.mp3\")  # Play sound for correct answer\n",
    "\n",
    "\n",
    "        display_lifeline_buttons()\n",
    "        disable_lifelines()\n",
    "\n",
    "    display(question_box)\n",
    "    display(output)\n",
    "\n",
    "\n",
    "def disable_lifelines():\n",
    "    global lifeline_used\n",
    "\n",
    "    \"\"\"Disables all lifeline buttons.\"\"\"\n",
    "    for button in lifeline_box.children:\n",
    "        if \"50:50\" in button.description and lifeline_used[\"50:50\"]:\n",
    "            button.disabled = True\n",
    "    \n",
    "        elif \"Buddy\" in button.description and lifeline_used[\"Buddy\"]:\n",
    "            button.disabled = True\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ask_question()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Series Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![xkcd comic](https://xkcdsw.com/content/img/2274.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "household_energy = pd.read_csv('household_energy.csv')\n",
    "household_energy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# create a list of all columns that we are considering\n",
    "# features = [ 'age', 'temp', 'weight', 'length' ]\n",
    "features = [ 'House_Size_m2', 'Appliances', 'Temperature_C', 'Energy_Consumption_kWh']\n",
    "\n",
    "# create all combinations of considered columns\n",
    "combinations = itertools.combinations(features, 2)\n",
    "\n",
    "# create a figure and specify its size\n",
    "fig = plt.figure(figsize=(15,10))\n",
    "\n",
    "# go through all combinations and create one plot for each\n",
    "figure_index = 1\n",
    "for combination in combinations:\n",
    "    # add a sub plot to the figure\n",
    "    axs = fig.add_subplot(2,3,figure_index)\n",
    "    \n",
    "    # plot the feature combination\n",
    "    # axs.scatter(fish[combination[0]], fish[combination[1]])\n",
    "    axs.scatter(household_energy[combination[0]], household_energy[combination[1]])\n",
    "\n",
    "    \n",
    "    # set the axis labels of the current sub plot\n",
    "    axs.set_xlabel(combination[0])\n",
    "    axs.set_ylabel(combination[1])\n",
    "        \n",
    "    # increase the figure index (otherwise all plots are drawn in the first subplot)\n",
    "    figure_index+=1\n",
    "\n",
    "    \n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To work with the timestamps, it is usually easier to transform them into ordered indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the 'Date' column to an integer sequence, where the first date is 1\n",
    "household_energy['Date'] = pd.to_datetime(household_energy['Date'])\n",
    "household_energy['Date_as_int'] = (household_energy['Date'] - household_energy['Date'].min()).dt.days + 1\n",
    "household_energy_IntDate = household_energy.drop(columns=['Date'])\n",
    "household_energy_IntDate.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot house size, appliances, temperature, and energy consumption with respect to the timestamps and check whether some patterns arise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = household_energy_IntDate.set_index('Date_as_int')\n",
    "\n",
    "\n",
    "# Create a figure with subplots\n",
    "fig, axs = plt.subplots(nrows=4, ncols=1, figsize=(10, 12), sharex=True)\n",
    "\n",
    "# List of the numeric feature columns\n",
    "features = df.columns  # This will automatically include the 4 numeric columns\n",
    "\n",
    "# Plot each feature in a separate subplot\n",
    "for i, feature in enumerate(features):\n",
    "    axs[i].plot(df.index, df[feature], label=feature)\n",
    "    axs[i].set_ylabel(feature)\n",
    "    axs[i].legend(loc=\"upper right\")\n",
    "    axs[i].grid(True)\n",
    "\n",
    "# Set the x-axis label\n",
    "plt.xlabel('Timestamp')\n",
    "\n",
    "# Display the plots\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Core Ideas of Time Series Analysis\n",
    "\n",
    "Time series data consists of observations collected over time, where the time-order of the data points plays a crucial role in identifying patterns and making predictions. Several key components often appear in time series data, each providing different insights:\n",
    "\n",
    "#### 1. **Trend**\n",
    "- A **trend** refers to the long-term movement or direction in the data over time.\n",
    "- **Example**: Climate change leading to a steady increase in global temperatures over decades is an example of a positive trend.\n",
    "\n",
    "  \n",
    "#### 2. **Seasonality**\n",
    "- **Seasonality** refers to periodic fluctuations in the data that repeat at regular intervals (e.g., daily, monthly, yearly).\n",
    "- **Example**: The alternating pattern of hot summers and cold winters is an example of seasonality in temperature data.\n",
    "\n",
    "#### 3. **Cyclicality**\n",
    "- **Cyclicality** refers to longer-term fluctuations that do not follow a fixed frequency but are driven by broader factors, often external events.\n",
    "- **Example**: The economic effects of the COVID-19 pandemic or the Ukraine war create cyclic patterns in global markets, with periods of recovery and contraction.\n",
    "\n",
    "#### 4. **Randomness (Noise)**\n",
    "- **Randomness** (also known as noise) represents the unpredictable, irregular variations in the data that cannot be explained by trends, seasonality, or cyclicality.\n",
    "- **Example**: Daily fluctuations in stock prices or weather variations not tied to a clear cause.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import numpy as np\n",
    "# Create data points as before\n",
    "n_points = 100\n",
    "time = np.arange(n_points)\n",
    "\n",
    "# Define components\n",
    "trend_component = time * 1.5\n",
    "seasonal_component = 30 * np.sin(time / 4)\n",
    "cyclical_component = 20 * np.sin(time / 20)\n",
    "random_component = np.random.normal(0, 5, n_points)\n",
    "\n",
    "# Create individual series\n",
    "trend = 100 + trend_component + np.random.normal(0, 3, n_points)\n",
    "seasonality = 100 + seasonal_component + np.random.normal(0, 2, n_points)\n",
    "cyclicality = 100 + cyclical_component + (time / 5) + np.random.normal(0, 3, n_points)\n",
    "noise = 100 + random_component\n",
    "combined = 100 + trend_component + seasonal_component + cyclical_component + random_component\n",
    "\n",
    "# Create subplots\n",
    "fig = make_subplots(rows=5, cols=1,\n",
    "                   subplot_titles=(\"1. Trend\", \"2. Seasonality\", \"3. Cyclicality\", \n",
    "                                   \"4. Randomness (Noise)\", \"Combined Components: Full Time Series\"))\n",
    "\n",
    "# Add traces for each component\n",
    "fig.add_trace(go.Scatter(x=time, y=trend, mode='lines', name='Trend', line=dict(color='#8884d8', width=2)), row=1, col=1)\n",
    "fig.add_trace(go.Scatter(x=time, y=seasonality, mode='lines', name='Seasonality', line=dict(color='#82ca9d', width=2)), row=2, col=1)\n",
    "fig.add_trace(go.Scatter(x=time, y=cyclicality, mode='lines', name='Cyclicality', line=dict(color='#8884d8', width=2)), row=3, col=1)\n",
    "fig.add_trace(go.Scatter(x=time, y=noise, mode='lines', name='Noise', line=dict(color='#ff7300', width=2)), row=4, col=1)\n",
    "\n",
    "# Add traces for combined view\n",
    "fig.add_trace(go.Scatter(x=time, y=100 + trend_component, mode='lines', name='Trend Component', \n",
    "                        line=dict(color='#8884d8', width=1.5)), row=5, col=1)\n",
    "fig.add_trace(go.Scatter(x=time, y=100 + trend_component + seasonal_component, mode='lines', \n",
    "                        name='Trend + Seasonal', line=dict(color='#82ca9d', width=1.5)), row=5, col=1)\n",
    "fig.add_trace(go.Scatter(x=time, y=100 + trend_component + cyclical_component, mode='lines', \n",
    "                        name='Trend + Cyclical', line=dict(color='#ffc658', width=1.5)), row=5, col=1)\n",
    "fig.add_trace(go.Scatter(x=time, y=combined, mode='lines', name='Complete Series', \n",
    "                        line=dict(color='#ff7300', width=3)), row=5, col=1)\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(height=1000, width=1000, showlegend=True)\n",
    "fig.update_layout(legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1.02, xanchor=\"right\", x=1))\n",
    "\n",
    "# Show plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time Series Decomposition\n",
    "\n",
    "Time series data can often be decomposed into these components to better understand the underlying patterns. There are two primary approaches to time series decomposition:\n",
    "\n",
    "#### 1. **Additive Model**\n",
    "In an **additive model**, the time series is assumed to be the sum of its components:\n",
    "\n",
    "$$\n",
    "Y_t = T_t + S_t + C_t + R_t\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $Y_t$ is the observed value at time $t$.\n",
    "- $T_t$ is the trend component.\n",
    "- $S_t$ is the seasonal component.\n",
    "- $C_t$ is the cyclic component.\n",
    "- $R_t$ is the residual (random noise).\n",
    "\n",
    "This model assumes that the variations due to trend, seasonality, and cyclicality are constant over time.\n",
    "\n",
    "**Example**: An additive model might work well for temperature data where the seasonal variation (difference between summer and winter) is consistent every year.\n",
    "\n",
    "#### 2. **Multiplicative Model**\n",
    "In a **multiplicative model**, the components are assumed to multiply together:\n",
    "\n",
    "$$\n",
    "Y_t = T_t \\times S_t \\times C_t \\times R_t\n",
    "$$\n",
    "\n",
    "This model is suitable when variations grow or shrink over time in a proportional way.\n",
    "\n",
    "**Example**: Sales of a product might exhibit multiplicative seasonality, where the effect of a holiday season increases sales more in years when the overall trend is higher.\n",
    "\n",
    "---\n",
    "\n",
    "#### When to Use Additive vs. Multiplicative Models\n",
    "\n",
    "- **Additive models** are used when the magnitude of seasonal fluctuations and random variations are constant over time.\n",
    "- **Multiplicative models** are used when seasonal fluctuations and variations increase or decrease in proportion to the trend.\n",
    "\n",
    "Understanding the components of time series data and how to decompose them is essential for accurate forecasting and interpretation of long-term patterns. We can use the ***statsmodels*** package for this.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "import datetime\n",
    "\n",
    "# Generate time series data\n",
    "np.random.seed(42)\n",
    "n_points = 144  # 12 years of monthly data\n",
    "\n",
    "# Create a pandas DataFrame with DateTime index\n",
    "start_date = datetime.datetime(2010, 1, 1)\n",
    "dates = [start_date + datetime.timedelta(days=30*i) for i in range(n_points)]\n",
    "years = np.arange(n_points) / 12\n",
    "\n",
    "# Components for additive model\n",
    "trend_linear = 10 + years * 5\n",
    "seasonality = 10 * np.sin(np.arange(n_points) * 2 * np.pi / 12)\n",
    "noise = np.random.normal(0, 1, n_points)\n",
    "additive_series = trend_linear + seasonality + noise\n",
    "\n",
    "# Components for multiplicative model\n",
    "trend_exp = 10 + 2 * np.exp(years / 6)\n",
    "seasonality_factor = 1 + 0.2 * np.sin(np.arange(n_points) * 2 * np.pi / 12)\n",
    "noise_factor = 1 + 0.05 * np.random.normal(0, 1, n_points)\n",
    "multiplicative_series = trend_exp * seasonality_factor * noise_factor\n",
    "\n",
    "# Create DataFrames\n",
    "df_add = pd.DataFrame({'value': additive_series}, index=dates)\n",
    "df_mult = pd.DataFrame({'value': multiplicative_series}, index=dates)\n",
    "\n",
    "# Use statsmodels for decomposition\n",
    "decomposition_add = seasonal_decompose(df_add, model='additive', period=12)\n",
    "decomposition_mult = seasonal_decompose(df_mult, model='multiplicative', period=12)\n",
    "\n",
    "# Create comparison figure\n",
    "fig_compare = make_subplots(rows=2, cols=1, \n",
    "                           subplot_titles=('Additive Model (Constant Variation)',\n",
    "                                          'Multiplicative Model (Proportional Variation)'))\n",
    "\n",
    "fig_compare.add_trace(go.Scatter(x=dates, y=additive_series, name='Additive', line=dict(color='blue')), row=1, col=1)\n",
    "fig_compare.add_trace(go.Scatter(x=dates, y=multiplicative_series, name='Multiplicative', line=dict(color='red')), row=2, col=1)\n",
    "\n",
    "fig_compare.update_layout(height=500, title_text=\"Comparing Additive vs. Multiplicative Time Series\")\n",
    "\n",
    "# Create additive decomposition figure\n",
    "fig_add = make_subplots(rows=4, cols=1, \n",
    "                       subplot_titles=('Original Time Series',\n",
    "                                     'Trend Component (T)',\n",
    "                                     'Seasonal Component (S)',\n",
    "                                     'Residual Component (R)'),\n",
    "                       shared_xaxes=True,\n",
    "                       vertical_spacing=0.05)\n",
    "\n",
    "fig_add.add_trace(go.Scatter(x=dates, y=decomposition_add.observed, name='Original', line=dict(color='blue')), row=1, col=1)\n",
    "fig_add.add_trace(go.Scatter(x=dates, y=decomposition_add.trend, name='Trend', line=dict(color='red')), row=2, col=1)\n",
    "fig_add.add_trace(go.Scatter(x=dates, y=decomposition_add.seasonal, name='Seasonal', line=dict(color='green')), row=3, col=1)\n",
    "fig_add.add_trace(go.Scatter(x=dates, y=decomposition_add.resid, name='Residual', line=dict(color='purple')), row=4, col=1)\n",
    "\n",
    "fig_add.update_layout(height=800, title_text=\"Additive Time Series Decomposition: Y = T + S + R\",\n",
    "                    legend_tracegroupgap=180)\n",
    "\n",
    "# Create multiplicative decomposition figure\n",
    "fig_mult = make_subplots(rows=4, cols=1, \n",
    "                        subplot_titles=('Original Time Series',\n",
    "                                      'Trend Component (T)',\n",
    "                                      'Seasonal Component (S)',\n",
    "                                      'Residual Component (R)'),\n",
    "                        shared_xaxes=True,\n",
    "                        vertical_spacing=0.05)\n",
    "\n",
    "fig_mult.add_trace(go.Scatter(x=dates, y=decomposition_mult.observed, name='Original', line=dict(color='blue')), row=1, col=1)\n",
    "fig_mult.add_trace(go.Scatter(x=dates, y=decomposition_mult.trend, name='Trend', line=dict(color='red')), row=2, col=1)\n",
    "fig_mult.add_trace(go.Scatter(x=dates, y=decomposition_mult.seasonal, name='Seasonal', line=dict(color='green')), row=3, col=1)\n",
    "fig_mult.add_trace(go.Scatter(x=dates, y=decomposition_mult.resid, name='Residual', line=dict(color='purple')), row=4, col=1)\n",
    "\n",
    "fig_mult.update_layout(height=800, title_text=\"Multiplicative Time Series Decomposition: Y = T × S × R\",\n",
    "                     legend_tracegroupgap=180)\n",
    "\n",
    "# Add annotations to explain the key differences\n",
    "fig_compare.add_annotation(x=dates[72], y=max(additive_series)*0.9,\n",
    "                          text=\"Constant seasonal variation\",\n",
    "                          showarrow=True,\n",
    "                          arrowhead=1,\n",
    "                          row=1, col=1)\n",
    "\n",
    "fig_compare.add_annotation(x=dates[72], y=max(multiplicative_series)*0.9,\n",
    "                          text=\"Proportional seasonal variation\",\n",
    "                          showarrow=True,\n",
    "                          arrowhead=1,\n",
    "                          row=2, col=1)\n",
    "\n",
    "# Display figures\n",
    "fig_compare.show()\n",
    "fig_add.show()\n",
    "fig_mult.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### --> The key difference you'll notice is that in the additive model, seasonal variations remain constant over time, while in the multiplicative model, they grow proportionally with the trend."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the seasonal_decompose() function to do this with our data as well!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "def decompose(data, period):\n",
    "    # Decompose the time series using the seasonal_decompose function\n",
    "    # Choose the 'Energy_Consumption_kWh' column as the series to decompose\n",
    "    decomposition = seasonal_decompose(data, period=period)\n",
    "    \n",
    "    # Create subplots for the decomposition and residual histogram\n",
    "    fig, axes = plt.subplots(nrows=5, ncols=1, figsize=(10, 12))\n",
    "    \n",
    "    # Plot the decomposed components\n",
    "    axes[0].plot(decomposition.observed, label='Observed')\n",
    "    axes[0].set_ylabel('Observed')\n",
    "    axes[0].legend(loc='upper right')\n",
    "    \n",
    "    axes[1].plot(decomposition.trend, label='Trend')\n",
    "    axes[1].set_ylabel('Trend')\n",
    "    axes[1].legend(loc='upper right')\n",
    "    \n",
    "    axes[2].plot(decomposition.seasonal, label='Seasonal')\n",
    "    axes[2].set_ylabel('Seasonal')\n",
    "    axes[2].legend(loc='upper right')\n",
    "    \n",
    "    axes[3].plot(decomposition.resid, label='Residuals')\n",
    "    axes[3].set_ylabel('Residuals')\n",
    "    axes[3].legend(loc='upper right')\n",
    "    \n",
    "    # Extract the residuals and remove NaN values\n",
    "    residuals = decomposition.resid.dropna()\n",
    "    \n",
    "    # Plot the histogram of residuals\n",
    "    axes[4].hist(residuals, bins=30, color='blue', edgecolor='black')\n",
    "    axes[4].set_ylabel('Frequency')\n",
    "    axes[4].set_xlabel('Residual Value')\n",
    "    axes[4].set_title('Distribution of Residuals')\n",
    "    \n",
    "    # Adjust the layout\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "decompose(data=df['Temperature_C'], period=366)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe that the distribution of residuals follows an approximately bell-shaped curve centered near zero. The highest frequency occurs around the zero mark, with roughly symmetrical tapering on both sides. The distribution extends primarily between -5 and +5, with the majority of values concentrated between -2 and +2. \n",
    "\n",
    "We can observe a slight negative skew in the distribution, as evidenced by a slightly longer tail on the left side compared to the right. The overall shape indicates that most of the residuals represent small random variations after the trend and seasonal components were removed from the original time series. The near-normal distribution suggests that the decomposition has effectively captured the systematic patterns in the data, leaving primarily random noise in the residuals.\n",
    "\n",
    "We can also observe that there are no major outliers or secondary peaks in the distribution, which would have indicated periods where the model failed to adequately capture the underlying patterns in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decompose(df['Energy_Consumption_kWh'], period=366)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe that the distribution of residuals displays a roughly symmetrical bell-shaped pattern centered around zero. The frequency peaks near the zero mark and gradually decreases on both sides. The residual values primarily fall within the range of -15 to +15, with the majority concentrated between -5 and +5.\n",
    "\n",
    "We can observe that the distribution appears approximately normal, which suggests that the time series decomposition has successfully captured the systematic components (trend and seasonality) of the data. The residuals represent the random variation that remains after accounting for these components.\n",
    "\n",
    "We can observe that the distribution appears slightly wider than in the previous example, indicating a higher degree of random variability in this time series. This is consistent with the residuals plot above, which shows fluctuations with greater amplitude.\n",
    "\n",
    "We can observe no significant skewness in the distribution, as both tails extend roughly equally, suggesting that the model doesn't systematically over-predict or under-predict values across the time series."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to Pick the Seasonality Parameter in Time Series Decomposition\n",
    "\n",
    "When performing time series decomposition using methods like `seasonal_decompose`, one of the key parameters you need to define is the **seasonality parameter**, often referred to as the **period**. The period is the number of time steps that define a complete seasonal cycle. Choosing the correct period is crucial for accurate decomposition and interpretation of seasonal components.\n",
    "\n",
    "#### 1. **Understand the Nature of Your Data**\n",
    "\n",
    "Before selecting a seasonality parameter, consider the type of data you are working with and what a \"season\" means in that context. Here are some examples:\n",
    "\n",
    "- **Daily Data**: If you have daily data, the seasonality could reflect weekly patterns (a period of 7 days) or yearly patterns (a period of 365 days).\n",
    "- **Monthly Data**: For monthly data, a common period would be 12 months to capture yearly seasonality.\n",
    "- **Quarterly Data**: If your data is collected on a quarterly basis, the period could be 4 (4 quarters in a year).\n",
    "\n",
    "#### 2. **Domain Knowledge**\n",
    "\n",
    "Leverage **domain knowledge** to make an informed choice about the period. Ask yourself the following questions:\n",
    "- Does the data exhibit cycles that repeat annually, monthly, or weekly?\n",
    "- Are there specific business cycles (e.g., quarterly sales reports, holiday seasons) that recur at predictable intervals?\n",
    "\n",
    "For instance, in climate data, a period of 12 months might make sense to capture the effect of seasons, whereas in retail sales, there might be cycles related to major holidays or events (e.g., Black Friday).\n",
    "\n",
    "#### 3. **Visual Inspection of the Data**\n",
    "\n",
    "Before setting a seasonality parameter, it can be helpful to **plot the time series** and visually inspect the data for repeating patterns. Plotting the data helps to detect regular intervals at which peaks or troughs occur, giving you clues about the period.\n",
    "\n",
    "If you are unsure about the period, you can use statistical tools such as the ***Autocorrelation Function (ACF) and Partial Autocorrelation Function (PACF)*** to identify ***potential seasonality***. These functions measure how correlated the time series is with its past values, and seasonal peaks often appear as significant spikes at lags corresponding to the seasonal period.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.plotting import autocorrelation_plot\n",
    "\n",
    "# Example: Plot autocorrelation\n",
    "autocorrelation_plot(df['Energy_Consumption_kWh'])\n",
    "plt.title('Autocorrelation Plot Energy_Consumption_kWh')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A quick note on lag\n",
    "\n",
    "Lag in time series analysis represents the time difference between data points being compared, with lag 1 comparing each point to its immediate predecessor. In autocorrelation plots, the x-axis shows different lag values while the y-axis displays correlation coefficients between the original series and its lagged version. Strong correlation at specific lags (like 7 for weekly patterns or 365 for annual patterns) reveals underlying seasonal cycles in the data. The autocorrelation plot for the energy consumption data shows significant peaks at lags 350-360, indicating an annual seasonal pattern if the data is recorded daily. Identifying these natural cycles through autocorrelation analysis helps determine the appropriate seasonality parameter for time series decomposition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Create a synthetic time series with yearly seasonality (365 days)\n",
    "def create_seasonal_data(days=1095):  # 3 years of data\n",
    "    # Date range\n",
    "    dates = pd.date_range(start='2020-01-01', periods=days)\n",
    "    \n",
    "    # Yearly seasonal pattern (365 days)\n",
    "    seasonal = 15 * np.sin(2 * np.pi * np.arange(days) / 365)\n",
    "    \n",
    "    # Add some noise and trend\n",
    "    noise = np.random.normal(0, 2, days)\n",
    "    trend = np.linspace(50, 70, days)\n",
    "    \n",
    "    # Combine components\n",
    "    values = trend + seasonal + noise\n",
    "    \n",
    "    return pd.Series(values, index=dates)\n",
    "\n",
    "# Create data\n",
    "data = create_seasonal_data()\n",
    "\n",
    "# Create figure with sliders\n",
    "fig = make_subplots(rows=2, cols=1, \n",
    "                    shared_xaxes=False,\n",
    "                    vertical_spacing=0.1,\n",
    "                    subplot_titles=(\"Original Time Series\", \"Original vs. Lagged Series\"),\n",
    "                    row_heights=[0.4, 0.6])\n",
    "\n",
    "# Add original time series\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=data.index, y=data, mode='lines', name='Original Series'),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "# Create empty traces for the overlay plot (will be updated by the slider)\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=data.index, y=data, mode='lines', name='Original', line=dict(color='blue')),\n",
    "    row=2, col=1\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=data.index, y=data, mode='lines', name='Lagged (365 days)', \n",
    "               line=dict(color='red', dash='dash')),\n",
    "    row=2, col=1\n",
    ")\n",
    "\n",
    "# Add annotation for correlation value\n",
    "fig.add_annotation(\n",
    "    x=0.5, y=0.55,\n",
    "    xref=\"paper\", yref=\"paper\",\n",
    "    text=f\"Correlation at lag 365: {np.corrcoef(data[365:], data[:-365])[0,1]:.3f}\",\n",
    "    showarrow=False,\n",
    "    font=dict(size=14)\n",
    ")\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    title=\"Understanding Lag in Time Series\",\n",
    "    height=700,\n",
    "    sliders=[{\n",
    "        'active': 365,\n",
    "        'currentvalue': {\"prefix\": \"Lag: \"},\n",
    "        'pad': {\"t\": 50},\n",
    "        'steps': [\n",
    "            {\n",
    "                'method': 'update',\n",
    "                'label': str(lag),\n",
    "                'args': [\n",
    "                    {\n",
    "                        'y': [\n",
    "                            data,  # Original time series (unchanged)\n",
    "                            data,  # Original series for comparison\n",
    "                            data.shift(lag)  # Shifted series based on lag\n",
    "                        ],\n",
    "                        'name': [\n",
    "                            'Original Series',\n",
    "                            'Original',\n",
    "                            f'Lagged ({lag} days)'\n",
    "                        ]\n",
    "                    },\n",
    "                    {\n",
    "                        'annotations': [{\n",
    "                            'x': 0.5, 'y': 0.55,\n",
    "                            'xref': \"paper\", 'yref': \"paper\",\n",
    "                            'text': f\"Correlation at lag {lag}: {np.corrcoef(data[lag:], data[:-lag])[0,1]:.3f}\" if lag < len(data) else \"Lag too large\",\n",
    "                            'showarrow': False,\n",
    "                            'font': {'size': 14}\n",
    "                        }]\n",
    "                    }\n",
    "                ]\n",
    "            } for lag in range(1, 731, 30)  # Lags from 1 to 730 (2 years) in steps of 30\n",
    "        ]\n",
    "    }]\n",
    ")\n",
    "\n",
    "fig.update_yaxes(title_text=\"Value\", row=1, col=1)\n",
    "fig.update_yaxes(title_text=\"Value\", row=2, col=1)\n",
    "fig.update_xaxes(title_text=\"Date\", row=2, col=1)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.plotting import autocorrelation_plot\n",
    "\n",
    "# Example: Plot autocorrelation\n",
    "autocorrelation_plot(df['Temperature_C'])\n",
    "plt.title('Autocorrelation Plot Temperature_C')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What Do Positive and Negative Peaks Indicate?\n",
    "\n",
    "#### Positive Peaks:\n",
    "A **positive peak** at a given lag indicates that there is a **positive correlation** between the time series values that are separated by that lag. This means that when the value at time $t$ is high, the value at time $t - \\text{lag}$ tends to be high as well, and vice versa for low values.\n",
    "\n",
    "**Example**: A positive peak at lag 12 in monthly data may indicate a yearly pattern where high values repeat every 12 months.\n",
    "\n",
    "#### Negative Peaks:\n",
    "A **negative peak** indicates a **negative correlation** between values at the given lag. This means that when the value at time $t$ is high, the value at time $t - \\text{lag}$ tends to be low, and vice versa. Negative correlations can often signify a reversing pattern or seasonal oscillation.\n",
    "\n",
    "**Example**: A negative peak at lag 6 in monthly data might indicate that high values tend to be followed by low values 6 months later (e.g., summer temperatures followed by winter).\n",
    "\n",
    "---\n",
    "\n",
    "### How to Use Positive and Negative Peaks in Practice\n",
    "\n",
    "#### 1. **Seasonality Detection**:\n",
    "- **Positive Peaks**: If there’s a significant positive peak at lag $s$ in the ACF plot, this could indicate seasonality with a period of $s$. For instance, in monthly data, a positive peak at lag 12 suggests yearly seasonality.\n",
    "- **Negative Peaks**: These may appear between seasonal peaks, especially when there's an oscillating pattern (e.g., higher values in summer and lower values in winter).\n",
    "\n",
    "#### 2. **Cyclic or Oscillating Patterns**:\n",
    "Repeated cycles of positive and negative peaks at regular intervals can indicate cyclic patterns. For example, alternating positive and negative peaks every 6 months might reflect a seasonal pattern in temperature (hot summer, cold winter).\n",
    "\n",
    "#### 3. **Trend Analysis**:\n",
    "In trending data, you may observe decaying positive autocorrelations at shorter lags (e.g., lag 1, lag 2, lag 3), followed by insignificant correlations at larger lags. ACF patterns like this suggest the presence of a trend.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import acf\n",
    "\n",
    "# Create synthetic beach resort sales data (5 years of monthly data)\n",
    "def create_beach_resort_data(months=60):\n",
    "    # Date range (monthly data)\n",
    "    dates = pd.date_range(start='2018-01-01', periods=months, freq='M')\n",
    "    \n",
    "    # Seasonal pattern (high in winter, low in summer)\n",
    "    time_index = np.arange(months)\n",
    "    # Create seasonality where December-February have high values, June-August have low values\n",
    "    seasonal = -20 * np.cos(2 * np.pi * time_index / 12)\n",
    "    \n",
    "    # Add yearly growth trend\n",
    "    trend = np.linspace(0, 10, months)\n",
    "    \n",
    "    # Add some random variation\n",
    "    noise = np.random.normal(0, 3, months)\n",
    "    \n",
    "    # Combine components (scale up to realistic sales numbers)\n",
    "    values = 50 + trend + seasonal + noise\n",
    "    \n",
    "    # Beach resorts have near-zero sales in summer, so apply a floor\n",
    "    values = np.maximum(values, 5)\n",
    "    \n",
    "    return pd.Series(values, index=dates)\n",
    "\n",
    "# Create data\n",
    "beach_sales = create_beach_resort_data()\n",
    "\n",
    "# Calculate autocorrelation function properly using statsmodels\n",
    "max_lag = 36\n",
    "acf_values = acf(beach_sales, nlags=max_lag, fft=True)\n",
    "\n",
    "# Create figure with sliders\n",
    "fig = make_subplots(rows=3, cols=1, \n",
    "                    shared_xaxes=False,\n",
    "                    vertical_spacing=0.1,\n",
    "                    subplot_titles=(\"Beach Resort Monthly Sales\", \n",
    "                                   \"Original vs. Lagged Series\", \n",
    "                                   \"Autocorrelation Function\"),\n",
    "                    row_heights=[0.3, 0.4, 0.3])\n",
    "\n",
    "# Add original time series\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=beach_sales.index, y=beach_sales, mode='lines', name='Monthly Sales',\n",
    "              line=dict(color='blue')),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "# Create empty traces for the overlay plot (will be updated by the slider)\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=beach_sales.index, y=beach_sales, mode='lines', name='Original', \n",
    "              line=dict(color='blue')),\n",
    "    row=2, col=1\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=beach_sales.index, y=beach_sales.shift(12), mode='lines', \n",
    "               name='Lagged (12 months)', line=dict(color='red', dash='dash')),\n",
    "    row=2, col=1\n",
    ")\n",
    "\n",
    "# Add autocorrelation plot - fixed to not be affected by slider\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=np.arange(len(acf_values)), y=acf_values, mode='lines+markers',\n",
    "              name='Autocorrelation', line=dict(color='green')),\n",
    "    row=3, col=1\n",
    ")\n",
    "\n",
    "# Add a marker to highlight the current lag on the ACF plot - this will be updated by the slider\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=[12], y=[acf_values[12]], mode='markers', \n",
    "               name='Current Lag', marker=dict(color='red', size=12, symbol='circle-open')),\n",
    "    row=3, col=1\n",
    ")\n",
    "\n",
    "# Add confidence interval lines for ACF\n",
    "conf_level = 1.96 / np.sqrt(len(beach_sales))\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=np.arange(len(acf_values)), y=[conf_level] * len(acf_values),\n",
    "              mode='lines', name='95% Confidence', line=dict(color='gray', dash='dash')),\n",
    "    row=3, col=1\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=np.arange(len(acf_values)), y=[-conf_level] * len(acf_values),\n",
    "              mode='lines', name='95% Confidence', line=dict(color='gray', dash='dash'),\n",
    "              showlegend=False),\n",
    "    row=3, col=1\n",
    ")\n",
    "\n",
    "# Initial lag and correlation\n",
    "initial_lag = 12\n",
    "initial_corr = np.corrcoef(beach_sales[initial_lag:], beach_sales[:-initial_lag])[0,1]\n",
    "\n",
    "# Add annotation for correlation value\n",
    "fig.add_annotation(\n",
    "    x=0.5, y=0.45,\n",
    "    xref=\"paper\", yref=\"paper\",\n",
    "    text=f\"Correlation at lag {initial_lag}: {initial_corr:.3f}\",\n",
    "    showarrow=False,\n",
    "    font=dict(size=14)\n",
    ")\n",
    "\n",
    "# Highlight key lags in ACF\n",
    "fig.add_annotation(\n",
    "    x=12, y=acf_values[12],\n",
    "    text=\"Yearly Pattern (Lag 12)\",\n",
    "    showarrow=True,\n",
    "    arrowhead=1,\n",
    "    row=3, col=1\n",
    ")\n",
    "\n",
    "fig.add_annotation(\n",
    "    x=6, y=acf_values[6],\n",
    "    text=\"Negative Correlation (Lag 6)\",\n",
    "    showarrow=True,\n",
    "    arrowhead=1,\n",
    "    row=3, col=1\n",
    ")\n",
    "\n",
    "# Slider steps\n",
    "slider_steps = []\n",
    "for lag in range(1, 25):  # Lags from 1 to 24 months\n",
    "    if lag < len(beach_sales):\n",
    "        corr = np.corrcoef(beach_sales[lag:], beach_sales[:-lag])[0,1]\n",
    "        step = {\n",
    "            'method': 'update',\n",
    "            'label': str(lag),\n",
    "            'args': [\n",
    "                {\n",
    "                    'y': [\n",
    "                        beach_sales,  # Original sales data (unchanged)\n",
    "                        beach_sales,  # Original series for comparison\n",
    "                        beach_sales.shift(lag),  # Shifted series based on lag\n",
    "                        acf_values,  # ACF values (unchanged)\n",
    "                        [acf_values[lag]]  # Update marker position\n",
    "                    ],\n",
    "                    'x': [\n",
    "                        beach_sales.index,  # Original sales data (unchanged)\n",
    "                        beach_sales.index,  # Original series for comparison\n",
    "                        beach_sales.index,  # Shifted series based on lag\n",
    "                        np.arange(len(acf_values)),  # ACF x values (unchanged)\n",
    "                        [lag]  # Update marker position\n",
    "                    ]\n",
    "                },\n",
    "                {\n",
    "                    'annotations': [{\n",
    "                        'x': 0.5, 'y': 0.45,\n",
    "                        'xref': \"paper\", 'yref': \"paper\",\n",
    "                        'text': f\"Correlation at lag {lag}: {corr:.3f}\",\n",
    "                        'showarrow': False,\n",
    "                        'font': {'size': 14}\n",
    "                    }]\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "        slider_steps.append(step)\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    title=\"beach Resort Sales: Identifying Seasonality through Lag Analysis\",\n",
    "    height=900,\n",
    "    sliders=[{\n",
    "        'active': 11,  # Default to yearly lag (0-indexed)\n",
    "        'currentvalue': {\"prefix\": \"Lag: \"},\n",
    "        'pad': {\"t\": 50},\n",
    "        'steps': slider_steps\n",
    "    }]\n",
    ")\n",
    "\n",
    "# Add horizontal line at y=0 for the ACF plot\n",
    "fig.add_shape(\n",
    "    type=\"line\", line=dict(color=\"black\", width=1),\n",
    "    x0=0, x1=max_lag, y0=0, y1=0,\n",
    "    row=3, col=1\n",
    ")\n",
    "\n",
    "# Axis labels\n",
    "fig.update_yaxes(title_text=\"Sales ($1000s)\", row=1, col=1)\n",
    "fig.update_yaxes(title_text=\"Sales ($1000s)\", row=2, col=1)\n",
    "fig.update_yaxes(title_text=\"Correlation\", range=[-1.1, 1.1], row=3, col=1)\n",
    "fig.update_xaxes(title_text=\"Month\", row=2, col=1)\n",
    "fig.update_xaxes(title_text=\"Lag (months)\", row=3, col=1)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Moving Averages for Data Smoothing\n",
    "\n",
    "**Moving Averages (MA)** are a simple yet powerful technique used to smooth time series data by reducing noise and short-term fluctuations, making it easier to observe long-term trends. \n",
    "\n",
    "#### What is a Moving Average?\n",
    "\n",
    "A **moving average** is calculated by taking the average of a fixed number of consecutive data points (the \"window\") and then sliding that window across the time series. At each step, the average of the window is computed and becomes the new smoothed data point. There are different types of moving averages:\n",
    "\n",
    "- **Simple Moving Average (SMA)**: \n",
    "  $$\n",
    "  \\text{SMA}_t = \\frac{y_t + y_{t-1} + \\dots + y_{t-n+1}}{n}\n",
    "  $$\n",
    "  Where $y_t$ is the value at time $t$, and $n$ is the size of the window. The SMA gives equal weight to all points within the window.\n",
    "\n",
    "- **Exponential Moving Average (EMA)**:\n",
    "  $$\n",
    "  \\text{EMA}_t = \\alpha \\cdot y_t + (1 - \\alpha) \\cdot \\text{EMA}_{t-1}\n",
    "  $$\n",
    "  Where $\\alpha$ is the smoothing factor (typically $\\alpha = \\frac{2}{n+1}$ for an $n$-period EMA). EMA gives more weight to recent observations, making it more responsive to recent changes in the data.\n",
    "\n",
    "#### Why is Smoothing Needed?\n",
    "\n",
    "Smoothing time series data with moving averages is important for several reasons:\n",
    "\n",
    "1. **Reducing Noise**: Time series data can be noisy, with short-term fluctuations obscuring the underlying trend. Smoothing reduces this noise and helps highlight important patterns.\n",
    "   \n",
    "2. **Revealing Trends**: By smoothing the data, long-term trends, seasonality, and cycles become easier to identify and analyze. This is particularly useful in fields like finance, sales forecasting, and weather analysis.\n",
    "\n",
    "3. **Improving Forecasting**: Smoothing can help improve the accuracy of forecasting models by focusing on the long-term pattern of the data, rather than reacting to short-term variations.\n",
    "\n",
    "#### Example:\n",
    "\n",
    "Imagine you're analyzing daily sales data. The sales fluctuate significantly from day to day due to various factors (promotions, weather, holidays), making it hard to see the overall trend. By applying a moving average, you can smooth out these daily fluctuations and observe a clearer trend of how sales are changing over time.\n",
    "\n",
    "In summary, **moving averages** help to reduce the noise in data, reveal long-term trends, and are often the first step in more advanced time series analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate synthetic daily sales data with noise\n",
    "def create_noisy_sales_data(days=365*2):  # 2 years of daily data\n",
    "    # Date range\n",
    "    dates = pd.date_range(start='2022-01-01', periods=days)\n",
    "    \n",
    "    # Time index\n",
    "    time_index = np.arange(days)\n",
    "    \n",
    "    # Multiple components\n",
    "    # Long-term trend\n",
    "    trend = 100 + time_index * 0.05\n",
    "    \n",
    "    # Yearly seasonality\n",
    "    yearly_seasonal = 30 * np.sin(2 * np.pi * time_index / 365)\n",
    "    \n",
    "    # Weekly seasonality (weekends higher)\n",
    "    weekly_pattern = np.zeros(days)\n",
    "    for i in range(days):\n",
    "        # Higher values on weekends (day 5 and 6 in zero-indexed week)\n",
    "        if i % 7 == 5 or i % 7 == 6:\n",
    "            weekly_pattern[i] = 15\n",
    "    \n",
    "    # Add substantial noise to make smoothing necessary\n",
    "    noise = np.random.normal(0, 15, days)\n",
    "    \n",
    "    # Combine components\n",
    "    values = trend + yearly_seasonal + weekly_pattern + noise\n",
    "    \n",
    "    return pd.Series(values, index=dates)\n",
    "\n",
    "# Create data\n",
    "daily_sales = create_noisy_sales_data()\n",
    "\n",
    "# Function to apply Simple Moving Average (SMA)\n",
    "def apply_sma(data, window):\n",
    "    return data.rolling(window=window, center=True).mean()\n",
    "\n",
    "# Calculate initial smoothed series with window=7 (weekly)\n",
    "initial_window = 7\n",
    "smoothed_sales = apply_sma(daily_sales, initial_window)\n",
    "\n",
    "# Create figure with sliders\n",
    "fig = make_subplots(rows=1, cols=1,\n",
    "                    subplot_titles=(\"Daily Sales Data with Moving Average Smoothing\"))\n",
    "\n",
    "# Add the original noisy data\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=daily_sales.index, y=daily_sales, mode='lines', \n",
    "               name='Raw Daily Sales', line=dict(color='lightgray', width=1))\n",
    ")\n",
    "\n",
    "# Add smoothed data\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=smoothed_sales.index, y=smoothed_sales, mode='lines', \n",
    "               name=f'{initial_window}-Day Moving Average', line=dict(color='blue', width=3))\n",
    ")\n",
    "\n",
    "# Calculate available moving average windows\n",
    "window_options = [1, 3, 7, 14, 30, 60, 90, 180, 365]\n",
    "\n",
    "# Create slider steps\n",
    "slider_steps = []\n",
    "for window in window_options:\n",
    "    smoothed = apply_sma(daily_sales, window)\n",
    "    step = {\n",
    "        'method': 'update',\n",
    "        'label': str(window),\n",
    "        'args': [\n",
    "            {\n",
    "                'y': [daily_sales, smoothed]\n",
    "            },\n",
    "            {\n",
    "                'traces': [0, 1],\n",
    "                'name': [f'Raw Daily Sales', f'{window}-Day Moving Average']\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "    slider_steps.append(step)\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    title=\"Effect of Moving Average Window Size on Data Smoothing\",\n",
    "    height=600,\n",
    "    width=1000,\n",
    "    xaxis_title=\"Date\",\n",
    "    yaxis_title=\"Sales\",\n",
    "    hovermode=\"x unified\",\n",
    "    legend=dict(\n",
    "        yanchor=\"top\",\n",
    "        y=0.99,\n",
    "        xanchor=\"left\",\n",
    "        x=0.01\n",
    "    ),\n",
    "    sliders=[{\n",
    "        'active': window_options.index(initial_window),\n",
    "        'currentvalue': {\"prefix\": \"Window Size: \", \"suffix\": \" days\"},\n",
    "        'pad': {\"t\": 50},\n",
    "        'steps': slider_steps\n",
    "    }]\n",
    ")\n",
    "\n",
    "# Add annotation to explain the effect\n",
    "fig.add_annotation(\n",
    "    x=0.5, y=0.05,\n",
    "    xref=\"paper\", yref=\"paper\",\n",
    "    text=\"Drag the slider to change the moving average window size.<br>Larger windows create smoother trends but introduce more lag.\",\n",
    "    showarrow=False,\n",
    "    font=dict(size=12),\n",
    "    align=\"center\",\n",
    "    bgcolor=\"rgba(255, 255, 255, 0.8)\",\n",
    "    bordercolor=\"gray\",\n",
    "    borderwidth=1,\n",
    "    borderpad=4\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "# For comparison, create a second visualization showing multiple smoothing levels at once\n",
    "fig2 = go.Figure()\n",
    "\n",
    "# Add original data\n",
    "fig2.add_trace(\n",
    "    go.Scatter(x=daily_sales.index, y=daily_sales, mode='lines', \n",
    "               name='Raw Data', line=dict(color='lightgray', width=1))\n",
    ")\n",
    "\n",
    "# Add different smoothing levels\n",
    "window_sizes = [7, 30, 90, 365]\n",
    "colors = ['blue', 'green', 'red', 'purple']\n",
    "\n",
    "for i, window in enumerate(window_sizes):\n",
    "    smoothed = apply_sma(daily_sales, window)\n",
    "    fig2.add_trace(\n",
    "        go.Scatter(x=smoothed.index, y=smoothed, mode='lines', \n",
    "                   name=f'{window}-Day MA', line=dict(color=colors[i], width=2))\n",
    "    )\n",
    "\n",
    "fig2.update_layout(\n",
    "    title=\"Comparison of Different Moving Average Window Sizes\",\n",
    "    height=600,\n",
    "    width=1000,\n",
    "    xaxis_title=\"Date\",\n",
    "    yaxis_title=\"Sales\",\n",
    "    hovermode=\"x unified\",\n",
    "    legend=dict(\n",
    "        yanchor=\"top\",\n",
    "        y=0.99,\n",
    "        xanchor=\"left\",\n",
    "        x=0.01\n",
    "    )\n",
    ")\n",
    "\n",
    "fig2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to use existing df variable with Energy_Consumption_kWh column\n",
    "energy_data = df['Energy_Consumption_kWh']\n",
    "\n",
    "# Function to apply Simple Moving Average (SMA)\n",
    "def apply_sma(data, window):\n",
    "    return data.rolling(window=window, center=True).mean()\n",
    "\n",
    "# Initial window size (80 as in your example)\n",
    "initial_window = 80\n",
    "smoothed_energy = apply_sma(energy_data, initial_window)\n",
    "\n",
    "# Create figure for interactive visualization\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add original data\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=energy_data.index, y=energy_data, mode='lines', \n",
    "               name='Original Energy Consumption', line=dict(color='blue', width=1))\n",
    ")\n",
    "\n",
    "# Add smoothed data\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=smoothed_energy.index, y=smoothed_energy, mode='lines', \n",
    "               name=f'{initial_window}-Point Moving Average', line=dict(color='red', width=2))\n",
    ")\n",
    "\n",
    "# Define window size options\n",
    "# Using logarithmic scale for window sizes to cover a wide range\n",
    "window_options = [1, 5, 10, 20, 40, 80, 160, 240, 320, 480]\n",
    "\n",
    "# Create slider steps\n",
    "slider_steps = []\n",
    "for window in window_options:\n",
    "    smoothed = apply_sma(energy_data, window)\n",
    "    step = {\n",
    "        'method': 'update',\n",
    "        'label': str(window),\n",
    "        'args': [\n",
    "            {\n",
    "                'y': [energy_data, smoothed]\n",
    "            },\n",
    "            {\n",
    "                'traces': [0, 1],\n",
    "                'name': [f'Original Energy Consumption', f'{window}-Point Moving Average']\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "    slider_steps.append(step)\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    title=\"Energy Consumption Smoothing with Adjustable Moving Average Window\",\n",
    "    height=600,\n",
    "    width=1000,\n",
    "    xaxis_title=\"Timestamp\",\n",
    "    yaxis_title=\"Energy Consumption (kWh)\",\n",
    "    hovermode=\"x unified\",\n",
    "    legend=dict(\n",
    "        yanchor=\"top\",\n",
    "        y=0.99,\n",
    "        xanchor=\"left\",\n",
    "        x=0.01\n",
    "    ),\n",
    "    sliders=[{\n",
    "        'active': window_options.index(initial_window),\n",
    "        'currentvalue': {\"prefix\": \"Window Size: \", \"suffix\": \" points\"},\n",
    "        'pad': {\"t\": 50},\n",
    "        'steps': slider_steps\n",
    "    }]\n",
    ")\n",
    "\n",
    "# Add annotation to explain the effect\n",
    "fig.add_annotation(\n",
    "    x=0.5, y=0.05,\n",
    "    xref=\"paper\", yref=\"paper\",\n",
    "    text=\"Drag the slider to change the moving average window size.<br>Larger windows create smoother trends but reduce responsiveness to recent changes.\",\n",
    "    showarrow=False,\n",
    "    font=dict(size=12),\n",
    "    align=\"center\",\n",
    "    bgcolor=\"rgba(255, 255, 255, 0.8)\",\n",
    "    bordercolor=\"gray\",\n",
    "    borderwidth=1,\n",
    "    borderpad=4\n",
    ")\n",
    "\n",
    "# Create comparison visualization with multiple window sizes\n",
    "fig2 = go.Figure()\n",
    "\n",
    "# Add original data\n",
    "fig2.add_trace(\n",
    "    go.Scatter(x=energy_data.index, y=energy_data, mode='lines', \n",
    "               name='Original Data', line=dict(color='blue', width=1))\n",
    ")\n",
    "\n",
    "# Add different smoothing levels\n",
    "comparison_windows = [10, 40, 80, 240]\n",
    "colors = ['red', 'orange', 'green', 'purple']\n",
    "\n",
    "for i, window in enumerate(comparison_windows):\n",
    "    smoothed = apply_sma(energy_data, window)\n",
    "    fig2.add_trace(\n",
    "        go.Scatter(x=smoothed.index, y=smoothed, mode='lines', \n",
    "                   name=f'{window}-Point MA', line=dict(color=colors[i], width=2))\n",
    "    )\n",
    "\n",
    "fig2.update_layout(\n",
    "    title=\"Comparison of Different Moving Average Window Sizes for Energy Consumption\",\n",
    "    height=600,\n",
    "    width=1000,\n",
    "    xaxis_title=\"Timestamp\",\n",
    "    yaxis_title=\"Energy Consumption (kWh)\",\n",
    "    hovermode=\"x unified\",\n",
    "    legend=dict(\n",
    "        yanchor=\"top\",\n",
    "        y=0.99,\n",
    "        xanchor=\"left\",\n",
    "        x=0.01\n",
    "    )\n",
    ")\n",
    "\n",
    "# Show figures\n",
    "fig.show()\n",
    "fig2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### As a reminder, before, our decomposition for energy consumption still contained a lot of noise after decomposition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "decompose(df['Energy_Consumption_kWh'], period=366)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's see whether the smoothing of the data affects the decomposition into trend seasonality, and residuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "temperature_C_SMA = df['Energy_Consumption_kWh'].rolling(window=7).mean()\n",
    "\n",
    "temperature_filled = temperature_C_SMA.bfill()\n",
    "\n",
    "decompose(temperature_filled, period=366)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stationarity in Time Series Analysis\n",
    "\n",
    "Stationarity is a fundamental concept in time series analysis. A stationary time series has statistical properties that do not change over time - specifically:\n",
    "\n",
    "1. **Constant Mean**: The average value remains consistent over time\n",
    "2. **Constant Variance**: The variation around the mean doesn't change over time\n",
    "3. **Constant Autocorrelation Structure**: The correlation between observations at different time lags remains constant\n",
    "\n",
    "Stationarity is crucial because:\n",
    "- Most time series models (including ARIMA) assume the data is stationary\n",
    "- It allows us to make reliable predictions since the underlying statistical properties aren't changing\n",
    "- It simplifies the mathematical treatment of the series\n",
    "\n",
    "### Types of Non-Stationarity\n",
    "\n",
    "1. **Trend Non-Stationarity**: The series has an upward or downward trend over time\n",
    "2. **Seasonal Non-Stationarity**: The series shows regular patterns at specific time intervals\n",
    "3. **Variance Non-Stationarity**: The variability of the series changes over time\n",
    "\n",
    "### Differencing to Achieve Stationarity\n",
    "\n",
    "Differencing is the primary technique used in ARIMA models to transform a non-stationary series into a stationary one. The \"I\" (Integrated) component in ARIMA indicates how many times differencing is applied.\n",
    "\n",
    "**First-order differencing** (d=1) computes the difference between consecutive observations:\n",
    "$$y'_t = y_t - y_{t-1}$$\n",
    "\n",
    "**Second-order differencing** (d=2) applies differencing twice:\n",
    "$$y''_t = y'_t - y'_{t-1} = (y_t - y_{t-1}) - (y_{t-1} - y_{t-2}) = y_t - 2y_{t-1} + y_{t-2}$$\n",
    "\n",
    "**Seasonal differencing** computes the difference between observations at seasonal intervals:\n",
    "$$y'_t = y_t - y_{t-s}$$\n",
    "where s is the seasonal period (e.g., 12 for monthly data with yearly seasonality).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Create time array\n",
    "time = np.arange(0, 200)\n",
    "\n",
    "# 1. Generate a stationary time series (white noise)\n",
    "stationary_series = np.random.normal(loc=10, scale=2, size=len(time))\n",
    "\n",
    "# 2. Generate a series with trend (non-stationary)\n",
    "trend = 0.05 * time\n",
    "trend_series = 10 + trend + np.random.normal(loc=0, scale=2, size=len(time))\n",
    "\n",
    "# 3. Generate a series with seasonality (non-stationary)\n",
    "seasonal_component = 5 * np.sin(2 * np.pi * time / 20)\n",
    "seasonal_series = 10 + seasonal_component + np.random.normal(loc=0, scale=1, size=len(time))\n",
    "\n",
    "# 4. Generate a series with both trend and seasonality\n",
    "trend_seasonal_series = 10 + trend + seasonal_component + np.random.normal(loc=0, scale=1, size=len(time))\n",
    "\n",
    "# 5. Generate a series with changing variance (non-stationary)\n",
    "variance_series = 10 + np.random.normal(loc=0, scale=1+time/50, size=len(time))\n",
    "\n",
    "# Create a dictionary of series for easier handling\n",
    "series_dict = {\n",
    "    \"Stationary (White Noise)\": stationary_series,\n",
    "    \"Trend (Non-stationary)\": trend_series,\n",
    "    \"Seasonal (Non-stationary)\": seasonal_series,\n",
    "    \"Trend + Seasonal (Non-stationary)\": trend_seasonal_series,\n",
    "    \"Changing Variance (Non-stationary)\": variance_series\n",
    "}\n",
    "\n",
    "# Function to apply differencing\n",
    "def difference_series(series, order=1):\n",
    "    \"\"\"Apply differencing of specified order to a series\"\"\"\n",
    "    diff_series = series.copy()\n",
    "    for i in range(order):\n",
    "        diff_series = np.diff(diff_series)\n",
    "    return diff_series\n",
    "\n",
    "# Create interactive plot\n",
    "fig = make_subplots(rows=2, cols=1, \n",
    "                    subplot_titles=(\"Original Time Series\", \"After Differencing\"),\n",
    "                    vertical_spacing=0.15,\n",
    "                    row_heights=[0.5, 0.5])\n",
    "\n",
    "# Add traces for each series\n",
    "for name, series in series_dict.items():\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=time, y=series, name=name, visible=(name==\"Trend (Non-stationary)\")),\n",
    "        row=1, col=1\n",
    "    )\n",
    "    \n",
    "    # Add differenced series (first order)\n",
    "    diff_series = difference_series(series)\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=time[1:], y=diff_series, name=f\"{name} (Differenced)\",\n",
    "                 visible=(name==\"Trend (Non-stationary)\")),\n",
    "        row=2, col=1\n",
    "    )\n",
    "\n",
    "# Create buttons for each series type\n",
    "buttons = []\n",
    "for i, name in enumerate(series_dict.keys()):\n",
    "    visibility = [False] * len(series_dict) * 2  # Two traces per series\n",
    "    visibility[i] = True  # Original series\n",
    "    visibility[i + len(series_dict)] = True  # Differenced series\n",
    "    \n",
    "    button = dict(\n",
    "        label=name,\n",
    "        method=\"update\",\n",
    "        args=[{\"visible\": visibility},\n",
    "              {\"title\": f\"Stationarity Demonstration: {name}\"}]\n",
    "    )\n",
    "    buttons.append(button)\n",
    "\n",
    "# Add dropdown menu\n",
    "fig.update_layout(\n",
    "    updatemenus=[{\n",
    "        'buttons': buttons,\n",
    "        'direction': 'down',\n",
    "        'showactive': True,\n",
    "        'x': 1,\n",
    "        'y': 1.15,\n",
    "    }]\n",
    ")\n",
    "\n",
    "# Add ADF test results annotation\n",
    "adf_results = {}\n",
    "for name, series in series_dict.items():\n",
    "    # Run ADF test on original\n",
    "    orig_result = adfuller(series)\n",
    "    orig_pvalue = orig_result[1]\n",
    "    orig_stationary = orig_pvalue < 0.05\n",
    "    \n",
    "    # Run ADF test on differenced\n",
    "    diff_result = adfuller(difference_series(series))\n",
    "    diff_pvalue = diff_result[1]\n",
    "    diff_stationary = diff_pvalue < 0.05\n",
    "    \n",
    "    adf_results[name] = {\n",
    "        'original': {'pvalue': orig_pvalue, 'stationary': orig_stationary},\n",
    "        'differenced': {'pvalue': diff_pvalue, 'stationary': diff_stationary}\n",
    "    }\n",
    "\n",
    "# Format the results as an annotation\n",
    "adf_text = \"Trend (Non-stationary):<br>\"\n",
    "adf_text += f\"  Original: {'Stationary' if adf_results['Trend (Non-stationary)']['original']['stationary'] else 'Non-stationary'} (p-value: {adf_results['Trend (Non-stationary)']['original']['pvalue']:.4f})<br>\"\n",
    "adf_text += f\"  Differenced: {'Stationary' if adf_results['Trend (Non-stationary)']['differenced']['stationary'] else 'Non-stationary'} (p-value: {adf_results['Trend (Non-stationary)']['differenced']['pvalue']:.4f})\"\n",
    "\n",
    "fig.add_annotation(\n",
    "    xref=\"paper\", yref=\"paper\",\n",
    "    x=0.5, y=-0.15,\n",
    "    text=adf_text,\n",
    "    showarrow=False,\n",
    "    bgcolor=\"rgba(255, 255, 255, 0.8)\",\n",
    "    bordercolor=\"black\",\n",
    "    borderwidth=1,\n",
    "    borderpad=4\n",
    ")\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    title=\"Stationarity Demonstration: Trend (Non-stationary)\",\n",
    "    height=700,\n",
    "    width=1500,\n",
    "    legend_title=\"Series Type\",\n",
    "    hovermode=\"x unified\"\n",
    ")\n",
    "\n",
    "# Update axes labels\n",
    "fig.update_xaxes(title_text=\"Time\", row=1, col=1)\n",
    "fig.update_xaxes(title_text=\"Time\", row=2, col=1)\n",
    "fig.update_yaxes(title_text=\"Value\", row=1, col=1)\n",
    "fig.update_yaxes(title_text=\"Differenced Value\", row=2, col=1)\n",
    "\n",
    "# Display plot\n",
    "fig.show()\n",
    "\n",
    "# Create rolling statistics plot for visual stationarity check\n",
    "def plot_rolling_stats(series_name):\n",
    "    series = series_dict[series_name]\n",
    "    \n",
    "    # Calculate rolling statistics\n",
    "    rolling_mean = pd.Series(series).rolling(window=20).mean()\n",
    "    rolling_std = pd.Series(series).rolling(window=20).std()\n",
    "    \n",
    "    # Create differenced series\n",
    "    diff_series = difference_series(series)\n",
    "    diff_rolling_mean = pd.Series(diff_series).rolling(window=20).mean()\n",
    "    diff_rolling_std = pd.Series(diff_series).rolling(window=20).std()\n",
    "    \n",
    "    # Create plot\n",
    "    fig = make_subplots(rows=2, cols=2, \n",
    "                       subplot_titles=(\"Original Series with Rolling Mean\", \n",
    "                                       \"Original Series with Rolling STD\",\n",
    "                                       \"Differenced Series with Rolling Mean\",\n",
    "                                       \"Differenced Series with Rolling STD\"),\n",
    "                       vertical_spacing=0.15,\n",
    "                       horizontal_spacing=0.1)\n",
    "    \n",
    "    # Original series with rolling mean\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=time, y=series, name='Original', line=dict(color='blue')),\n",
    "        row=1, col=1\n",
    "    )\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=time, y=rolling_mean, name='Rolling Mean (window=20)', \n",
    "                  line=dict(color='red', dash='dash')),\n",
    "        row=1, col=1\n",
    "    )\n",
    "    \n",
    "    # Original series with rolling std\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=time, y=series, name='Original', showlegend=False, line=dict(color='blue')),\n",
    "        row=1, col=2\n",
    "    )\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=time, y=rolling_std, name='Rolling STD (window=20)', \n",
    "                  line=dict(color='green', dash='dash')),\n",
    "        row=1, col=2\n",
    "    )\n",
    "    \n",
    "    # Differenced series with rolling mean\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=time[1:], y=diff_series, name='Differenced', line=dict(color='purple')),\n",
    "        row=2, col=1\n",
    "    )\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=time[1:], y=diff_rolling_mean, name='Diff Rolling Mean', \n",
    "                  line=dict(color='orange', dash='dash')),\n",
    "        row=2, col=1\n",
    "    )\n",
    "    \n",
    "    # Differenced series with rolling std\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=time[1:], y=diff_series, name='Differenced', showlegend=False, \n",
    "                  line=dict(color='purple')),\n",
    "        row=2, col=2\n",
    "    )\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=time[1:], y=diff_rolling_std, name='Diff Rolling STD', \n",
    "                  line=dict(color='brown', dash='dash')),\n",
    "        row=2, col=2\n",
    "    )\n",
    "    \n",
    "    # Update layout\n",
    "    fig.update_layout(\n",
    "        title=f\"Rolling Statistics: {series_name}\",\n",
    "        height=800,\n",
    "        width=800,\n",
    "        hovermode=\"x unified\"\n",
    "    )\n",
    "    \n",
    "    # Display plot\n",
    "    fig.show()\n",
    "\n",
    "# Create rolling statistics plot for the trend series\n",
    "plot_rolling_stats(\"Trend (Non-stationary)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pen & Paper Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### P&P (1) 3-Year Simple Moving Average Forecast\n",
    "\n",
    "In this exercise, we calculate the 3-year Simple Moving Average (SMA) forecast for a set of sales data over 12 years. The Simple Moving Average helps smooth out short-term fluctuations by averaging the data over a fixed window of time.\n",
    "\n",
    "#### Example Data\n",
    "\n",
    "| Year | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 | 10 | 11 | 12 |\n",
    "|------|---|---|---|---|---|---|---|---|---|----|----|----|\n",
    "| Sales ($y$) | 5.2 | 4.9 | 5.5 | 4.9 | 5.2 | 5.7 | 5.4 | 5.8 | 5.9 | 6.0 | 5.2 | 4.8 |\n",
    "\n",
    "#### 3-Year Simple Moving Average Calculation\n",
    "\n",
    "The 3-year Simple Moving Average (SMA) is calculated by taking the average of sales values over 3 consecutive years:\n",
    "\n",
    "$$\n",
    "\\text{SMA}_t = \\frac{y_t + y_{t-1} + y_{t-2}}{3}\n",
    "$$\n",
    "\n",
    "Let's calculate the 3-year moving average step-by-step for the data and derive the errors $e_t = y_t - \\text{SMA}_t$ per year as well as the corresponding mean squared error.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### P&P (1) Solution "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Moving Average (SMA) Analysis for Sales Data\n",
    "\n",
    "#### Table 1: 3-Year Moving Average Calculation\n",
    "\n",
    "| Year | Sales ($y$) | 3-Year Moving Total | 3-Year Moving Average |\n",
    "|:----:|------------:|--------------------:|----------------------:|\n",
    "|  1   |        5.2  |         —           |           —           |\n",
    "|  2   |        4.9  |         —           |           —           |\n",
    "|  3   |        5.5  |        15.6         |          5.20         |\n",
    "|  4   |        4.9  |        15.3         |          5.10         |\n",
    "|  5   |        5.2  |        15.6         |          5.20         |\n",
    "|  6   |        5.7  |        15.8         |          5.27         |\n",
    "|  7   |        5.4  |        16.3         |          5.43         |\n",
    "|  8   |        5.8  |        16.9         |          5.63         |\n",
    "|  9   |        5.9  |        17.1         |          5.70         |\n",
    "| 10   |        6.0  |        17.7         |          5.90         |\n",
    "| 11   |        5.2  |        17.1         |          5.70         |\n",
    "| 12   |        4.8  |        16.0         |          5.33         |\n",
    "\n",
    "#### Table 2: Error Calculation and Analysis\n",
    "\n",
    "| Year | Sales ($y$) | 3-Year Moving<br>Average | Error<br>$(e = y - \\text{SMA})$ | Absolute<br>Error $\\|e\\|$ | Squared<br>Error $e^2$ | Percentage<br>Error $\\|e\\|/y$ (%)|\n",
    "|:----:|------------:|-------------------------:|--------------------------------:|-------------------------:|-----------------------:|---------------------------------:|\n",
    "|  1   |        5.2  |            —            |                —                |            —            |           —           |                —                |\n",
    "|  2   |        4.9  |            —            |                —                |            —            |           —           |                —                |\n",
    "|  3   |        5.5  |          5.20           |             +0.30              |          0.30           |         0.09          |              5.45%              |\n",
    "|  4   |        4.9  |          5.10           |             -0.20              |          0.20           |         0.04          |              4.08%              |\n",
    "|  5   |        5.2  |          5.20           |              0.00              |          0.00           |         0.00          |              0.00%              |\n",
    "|  6   |        5.7  |          5.27           |             +0.43              |          0.43           |         0.18          |              7.54%              |\n",
    "|  7   |        5.4  |          5.43           |             -0.03              |          0.03           |         0.00          |              0.56%              |\n",
    "|  8   |        5.8  |          5.63           |             +0.17              |          0.17           |         0.03          |              2.93%              |\n",
    "|  9   |        5.9  |          5.70           |             +0.20              |          0.20           |         0.04          |              3.39%              |\n",
    "| 10   |        6.0  |          5.90           |             +0.10              |          0.10           |         0.01          |              1.67%              |\n",
    "| 11   |        5.2  |          5.70           |             -0.50              |          0.50           |         0.25          |              9.62%              |\n",
    "| 12   |        4.8  |          5.33           |             -0.53              |          0.53           |         0.28          |             11.04%              |\n",
    "| **Total** |        |                         |                                |        **2.46**         |       **1.20**        |            **46.28%**           |\n",
    "\n",
    "#### Summary of Forecasting Error Metrics\n",
    "\n",
    "| Error Metric | Formula | Calculation | Result |\n",
    "|:-------------|:--------|:------------|:-------|\n",
    "| **Mean Absolute Error (MAE)** | $\\frac{1}{n}\\sum\\|e_i\\|$ | $\\frac{2.46}{10}$ | **0.246** |\n",
    "| **Mean Squared Error (MSE)** | $\\frac{1}{n}\\sum e_i^2$ | $\\frac{1.20}{10}$ | **0.120** |\n",
    "| **Root Mean Squared Error (RMSE)** | $\\sqrt{\\text{MSE}}$ | $\\sqrt{0.120}$ | **0.346** |\n",
    "| **Mean Absolute Percentage Error (MAPE)** | $\\frac{1}{n}\\sum(\\frac{\\|e_i\\|}{y_i})$ | $\\frac{46.28\\%}{10}$ | **4.63%** |\n",
    "\n",
    "#### Interpretation\n",
    "\n",
    "The error metrics provide a quantitative assessment of the 3-year Simple Moving Average (SMA) forecast:\n",
    "\n",
    "- **MAE (0.246)**: On average, the forecast deviates from actual sales by 0.246 units.\n",
    "- **RMSE (0.346)**: Slightly higher than MAE, indicating some larger errors are present.\n",
    "- **MAPE (4.63%)**: The forecast is off by approximately 4.63% on average, suggesting relatively good accuracy.\n",
    "\n",
    "The low MAPE value indicates that the 3-year moving average provides a reasonable forecast for this sales data, with predictions typically within 5% of actual values."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
